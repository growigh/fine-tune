{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Holographic display technology]\n[Opening punch] — Tokyo startup Polalgraph created a portal-like holographic display.\n[Why it matters] — Holograms have been a marketing gimmick for a decade.\n[What’s new] —Tracks head and eye movements to create a 3D, parallax view.Lightweight glasses, Vive tracker/webcam, and a 3D projector/monitor are used.\n[Future outlook] —Virtual cities and games like Age of Empires are possible.\n[Vision] —Immersive virtual experiences.\n[Closer] —Stepping inside virtual cities is near."}, {"role": "assistant", "content": "This technology from Star Wars just became real. For almost a decade, holograms have been a marketing gimmick. But what this Tokyo based startup Polalgraph has built feels like a portal to another world. Let me explain. So the core idea behind what Portal has done is that if you can track a person's head in 3D space, you can also track their eyes and render the scene from each point of view. Merge these two POVs together and the screen becomes a window almost like a portal. One you can peer around, lean into or walk past. You just put on a pair of lightweight LCD shutter glasses, while a Vive tracker or a webcam tracks your head. Then a 3D projector or monitor shows you two slightly different images, one for each eye, sync to your exact head position. The result, realtime motion parallax and depth. Lean left and you see behind the virtual object. Crouch and you're looking under it. Recently, they also showed off their flagship demo called Geoportal. It almost looks like a sand table, but what's projected onto it is a full-blown 3D miniature city. Now, with the speed technologies moving, I don't think we're far away from actually stepping inside virtual cities or maybe even playing Age of Empires on the table against our"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Code Rabbit AI tool for GitHub]\n[Opening punch] — Code Rabbit AI agent for GitHub pull requests\n[Why it matters] — Endless PR review cycles, slow code shipping\n[What’s new] — AI agent plans fixes, creates pull requests, shows steps, searches for solutions, scans codebase, free for open-source\n[Future outlook] — Faster code shipping, improved collaboration\n[Vision] — Stop endless PR review cycles, ship better code faster\n[Closer] — Code Rabbit partners with us for faster code shipping"}, {"role": "assistant", "content": "Imagine if you had an AI agent inside GitHub that could understand your code, plan fixes, and even create pull requests for you all from a single comment. Turns out Code Rabbit has this interesting feature called agentic chat. And it's kind of insane what it can do. So, let's use it and see how it performs. Let's open a GitHub repository and create a pull request. Now, all I'm going to do is write at Code Rabbit AI plan and let it do its thing. As you can see, it's analyzing the review comment and planning the necessary code changes, all without us having to leave the PR thread. Not just that, it's also showing every step before executing anything. So, we can tweak or edit as we want. It can even search the web for Stack Overflow answers or scan your own codebase for dependencies, all without ever leaving the thread. And the best part, it's absolutely free for all open-source projects and trusted by over 5,000 companies. Finally, with Code Rabbit's agentic capabilities, you can stop sitting through endless PR review cycles and start shipping better code faster right inside your GitHub. Thank you to Code Rabbit for partnering with us on today's"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Google's Android XR glasses launch at IO 2025]\n[Opening punch] — Google unveils Android XR glasses, combining navigation, real-time translation, and AI.\n[Why it matters] — Current communication and navigation methods are often cumbersome and limited.\n[What’s new] — Glasses feature a hidden display for navigation (Google Maps), real-time translation, and Gemini AI for helpful information based on location and direction.\n[Future outlook] — Glasses are built with Samsung and Qualcomm, designed to work with phones.\n[Vision] — Glasses could revolutionize communication across language barriers and navigation.\n[Closer] — Stylish design, no more clunky tech."}, {"role": "assistant", "content": "Google just unveiled their Android XR glasses at IO 2025, and they look like regular glasses, but pack some seriously cool tech. First up, see how they handle navigation. So, I'm wearing the new glasses, which has a screen. You can't see it, but I'm actually navigating Google Maps as we speak. This is what I see. By the way, I see this. So, I can actually navigate. I just have to look down. And when I'm looking down, you can see that I'm actually navigating. I'm just going to turn. Next up is their realtime translation. This is something which blew my[Music] mind. As you can see, the translation happens instantly. The glasses can understand multiple languages and show you what's being said right in your field of view. This could completely change how we communicate across language barriers. Now, what makes these special is that they combine cameras, microphones, speakers, and a hidden display that only you can see. Google built these with Samsung and Qualcomm, creating a new Android XR platform that's designed to work perfectly with your phone. Plus, with Gemini AI built-in, the glasses can see what you're looking at and provide helpful information right when you need it. They understand your location and which way you're facing, so directions appear exactly when and where you need them. The best part, Google's partnering with Wobbby Parker and Gentle Monster, so these will actually look stylish. No more clunky tech."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Google AI advancements at Google IO 2025 keynote]\n\n[Opening punch] — Google is unveiling major AI advancements, including Gemini 2.5 upgrades, agent capabilities, generative media models, and AI filmmaking tools.\n\n[Why it matters] — Current AI models have limitations in handling complex tasks, and AI-powered assistance in various areas is still developing.\n\n[What’s new] — Gemini 2.5 Pro's Deep Think enhances reasoning; Gemini agents can handle multiple tasks; AI shopping features allow virtual try-ons; generative media models (Imagine 4, V3) create stunning images and videos with audio; Flow is an AI filmmaking tool; Jules is an asynchronous coding agent; Android XR brings Gemini to glasses and headsets; Beam is an AI-first 3D video communication platform.\n\n[Future outlook] —AI tools are becoming more capable and integrated into various aspects of life, including shopping, filmmaking, and communication.\n\n[Vision] — AI is becoming more intelligent, agentic, and personalized, automating tasks and enhancing user experiences across multiple sectors.\n\n[Closer] —The advancements are not incremental but represent significant progress in AI capabilities."}, {"role": "assistant", "content": "Ladies and gentlemen, we're at Google IO. Let's do a quick wrap. And I'm about to break down everything mind-blowing from the 2025 keynote in just a quick minute. Now, Google is going allin on AI that is more intelligent, agentic, and personalized than ever before. First, they're improving their most intelligent models. Gemini 2.5 Flash and Pro are getting major upgrades. The standout is Deep Think, a new enhanced reasoning mode in Gemini 2.5 Pro that can tackle super complex math and coding tasks through parallel thinking. Next up, Gemini powered agents are next level this year. Project Mariner can now juggle up to 10 tasks at once, learns workflows after you teach it just once, and powers the new agent mode inside the Gemini app. Think finding apartments, booking tours, or handling forms automatically. Plus, what's really cool is you'll soon be able to shop with AI, including virtually trying on clothes from your own photos with just a single upload. They're also launching impressive generative media models. Imagine 4 creates stunning images with better text rendering. While V3 is the first video model with native audio generation, adding environmental sounds and even dialogue to videos. Now, Google is also introducing Flow, a new AI filmmaking tool designed specifically for their advanced models that helps storytellers create cinematic clips and scenes without complicated production. For developers, Jules is now available in public beta. It's an asynchronous coding agent that integrates directly with repositories and handles tasks on your behalf. Then we have Android XR which is bringing Gemini to glasses and headsets. These smart glasses come with cameras, microphones, and an optional inland lens display working with your phone to give you hands-free AI assistance. Google is partnering with Wobbby Parker and Gentle Monster to make stylish versions. Finally, let's not forget Beam, previously called Project Starline. This AI first 3D video communication platform creates remarkably lielike conversations with speech translation capabilities. You see, I was at Google IO again this time and got my hands on some of these tools and demos. Trust me, this isn't just incremental progress."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Difficulty landing tech jobs for freshers due to stagnant hiring by major tech companies.\n\n[Opening punch] — Major tech companies (Google, Microsoft, Apple, Tesla, Meta, Nvidia, Palanteer) have seen zero net growth in hiring over the past 3 years.\n\n[Why it matters] —A massive hiring spree occurred in 2022, followed by job cuts in 2023, creating a challenging job market for freshers.\n\n[What’s new] —Four fundamental changes are driving this: overhiring during low-interest periods, pressure to improve operating margins, investment in generative AI infrastructure, and AI productivity tools enabling increased output with existing staff.\n\n[Future outlook] —Tech companies are experimenting with growing revenue without increasing headcount, potentially ending the hypergrowth hiring era.\n\n[Vision] —AI productivity tools are changing the relationship between revenue growth and headcount growth, potentially altering the future of hiring in the tech industry.\n\n[Closer] — The era of hypergrowth hiring in tech may be ending."}, {"role": "assistant", "content": "Have you noticed it's gotten way harder to land a tech job as a fresher? According to data from DD, the biggest tech companies, Google, Microsoft, Apple, Tesla, Meta, Nvidia, and Palanteer have had zero net growth in hiring over the last 3 years. That's right, zero growth. The total headcount today is basically the same as it was 3 years ago. So, what exactly is happening during the pandemic? These companies went on a massive hiring spree. Just look at this graph. That huge spike in 2022, that's when they collectively added over 120,000 employees in a single year. But then in 2023, we actually saw negative growth with companies cutting jobs. But the big question is, how are these tech giants growing their businesses without growing their teams? It boils down to these four fundamental changes. First, they overhired during the zero interest rate pandemic years between 2020 and 2022, assuming the demand boom would continue long-term. It did not. Second, with higher interest rates now, CFOs are under intense pressure to improve operating margins, and keeping headcount flat is the most direct way to boost those numbers. Third, these companies are investing billions in generative AI infrastructure. The cost of capital for these chips and systems is enormous, leaving less budget for new hires. Fourth, there's emerging evidence that AI productivity tools might already be enabling these companies to accomplish more with their existing workforce. This last point is actually huge because it's changing a fundamental relationship in business. The data historically showed that if a company's revenue grew by 10%, its headcount would also grow by about 10%. But these AI productivity gains are breaking that pattern. Now these tech leaders are testing whether they can grow revenue without growing headcount at all. This represents the potential end of the hyperrowth hiring era that defined tech from 2010 to 2021."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Fortnite's AI-powered Darth Vader character is being manipulated by players.\n\n[Opening punch] — Players are manipulating Darth Vader's AI responses in Fortnite.\n\n[Why it matters] —Millions of children play Fortnite, and inappropriate content exposure is a concern.\n\n[What’s new] — Players are exploiting loopholes in the AI's language understanding to get unexpected responses.\n\n[Future outlook] — Epic Games has patched the issue and added safety checks.\n\n[Vision] —AI interactions in games need safeguards to prevent misuse and inappropriate content.\n\n[Closer] — The future of AI in gaming is uncertain, and further development is needed."}, {"role": "assistant", "content": "Fortnite's Darth Vader just got jailbroken and people are making it say anything they want. I find your enthusiasm unsettling Peter Griffin and gooning gang. Explain this adolescent term. Now, we can't tell you what it means for obvious reasons, but it shows Peter Griffin holding a lightsaber and facing off with Darth Vader. But instead of Vader saying something serious like he usually does, he says something totally unexpected. So, how did this happen? Well, it's because Epic Games added characters like Darth Vader using AI so players could interact with them. According to Fortnite's website, when players talk to Darth Vader, their voice gets converted into text and fed into Google's Gemini, which writes a reply matching Darth Vader's personality. Then 11 Labs, a texttovoice model, takes that reply and speaks it out loud in Vader's voice. Now, that's what should have happened ideally, but players quickly realized that by asking Vader to repeat after me or using clever replies, they could bypass Fortnite's filters and trick Gemini into saying almost anything they want. In other words, they weren't exactly hacking the system, but manipulating Gemini by finding loopholes in how LLM understand language. While this might be funny to some, remember that Fortnite is played by millions of kids as well, and pre-exposing them to such stuff probably isn't good for them. Epic Games says they've now fixed the issue with a hot fix and added more safety checks. Like, if a player is under 13, they cannot talk to these AI characters without parental consent. But it'll be interesting to see what happens"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI launches Codeex, a software engineering agent]\n[Opening punch] — OpenAI launches Codeex, a software engineering agent.\n[Why it matters] — Current software development relies heavily on human coding.\n[What’s new] — Codeex is a cloud-based agent that performs coding tasks like writing features, fixing bugs, and refactoring. It runs in isolated environments, accesses codebases through ChatGPT sidebar, and prepares pull requests.\n[Future outlook] — Available now for ChatGPT Pro and enterprise users, with Plus user support coming soon.\n[Vision] — Shifts software development from pure human coding to human-AI collaboration, reducing text_input switching and automating background tasks.\n[Closer] — Represents a significant shift in software development."}, {"role": "assistant", "content": "OpenAI just launched Codeex, a software engineering agent that runs in the cloud and does tasks for you, like writing a new feature or fixing a bug. You can even run multiple tasks in parallel, each in its own isolated environment. You can access Codeex through chat GPT sidebar and assign new coding tasks by typing a prompt and clicking code. If you want to ask Codeex a question about your codebase, click ask. Each task is processed independently in a separate isolated environment pre-loaded with your codebase. Technically, Codeex is powered by Codeex 1, a specialized model built on OpenAI's 03 architecture, but optimized specifically for software engineering. It can perform tasks in real time by reading your codebase, creating changes in a sandboxed environment, running tests to verify its work, and then preparing pull requests. The system works by preloading your repository into an isolated container where Codeex can execute commands, modify files, and validate changes through your existing test suite. There's no internet access during execution, just your code and pre-installed dependencies. What's fascinating is how teams are already using it. Companies like Cisco and Temporal are offloading repetitive tasks like refactoring and test writing, while superhuman found it's helping product managers contribute lightweight code changes without pulling engineers away from core work. What's interesting is how Codex is solving two problems at once. It's reducing text_input switching for developers and automating background work that would otherwise break focus. It's available now for chat GPT pro team and enterprise users with support for plus users coming soon. This tech represents a significant shift in how we approach software development from pure human coding to human AI collaboration."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Apple's App Store commission policy change and Epic Games lawsuit resolution]\n\n[Opening punch] — Apple, developers, Epic Games, Fortnite; Apple's 30% App Store commission challenged and resolved.\n\n[Why it matters] — Developers frustrated by 30% commission, seeking alternative payment methods; Apple's control over in-app transactions.\n\n[What’s new] — Apple's 30% commission on in-app purchases is eliminated; developers can now direct users to external payment options without penalty; Fortnite potentially returning to the App Store.\n\n[Future outlook] —Developers can build apps without losing a third of their revenue; potential for increased indie app development.\n\n[Vision] —A more competitive and potentially more innovative app ecosystem; reduced financial burden on developers.\n\n[Closer] —Fortnite's potential return and broader implications for the app development landscape."}, {"role": "assistant", "content": "Apple has finally listened to developers and the Apple tax is going away. And guess what? Fortnite might finally be coming back. So, it all started in 2008 when Apple launched the App Store and introduced a 30% commission on almost everything sold through the app. Suboutputions, game purchases, inapp upgrades, you name it. And to be fair, it made sense, too. After all, Apple was offering a massive marketplace and helping developers make millions. But as the app economy exploded, developers started getting frustrated with Apple's 30% cut. So, they found a clever trick. They'd used the app store to get traction, but then nudge users to their own websites to make the payments. This meant that Apple could no longer get its cut, something Apple did not tolerate. So, they started blocking developers from telling users about cheaper payment options outside the app. Now, when this reached the court, Apple was forced to allow developers to redirect users again. But this is where Apple did something sneaky. Yes, the developers could now redirect users to external links, but Apple would still charge a 27% cut since Apple believed it facilitated the transaction. And that's where Epic Games stepped in. They did something nobody would even dare of doing against Apple. They built their own inapp payment system called Epic Direct Payment inside Fortnite, bypassing Apple completely within the app itself. So, in classic Apple fashion, Fortnite was kicked off the app store immediately, and thus began the iconic Epic Games versus Apple lawsuit. Epic argued Apple was abusing its monopoly, while Apple said it was just protecting its users. But after years of constant back and forth, Epic Games finally won on April 30th, 2025, and they won big. So big that Fortnite might eventually be coming back. Even though Apple has filed an appeal against this contempt ruling last week, Epic's win could change everything for developers. With Apple no longer taking its cut, developers can finally build apps without worrying about losing a third of their revenue, eventually motivating more indie developers to build apps."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Neuralink technology demonstration]\n\n[Opening punch] — Brad, an ALS patient, edits a video using only his thoughts via Neuralink.\n\n[Why it matters] — Current limitations of communication for people with severe disabilities.\n\n[What’s new] — Tiny chip with electrodes in brain's motor cortex decodes neural activity into precise cursor movements and clicks, enabling real-time thought-controlled actions.AI voice cloning used.\n\n[Future outlook] — Potential for direct brain-to-brain communication, near-zero information loss.\n\n[Vision] — Revolutionizing human communication, enabling people with disabilities to interact with the world in new ways.\n\n[Closer] —Exciting and scary future of human communication."}, {"role": "assistant", "content": "You're looking at the first ever video edited using only thoughts. This is the first video edited with the Neuralink. This is my old voice narrating this video cloned by AI from recordings before I lost my voice. This is Brad, an ALS patient who can't move or speak, but can somehow control his MacBook using just his thoughts thanks to Neuralink. It all starts with a tiny coinsized chip placed inside Brad's motor cortex, the part of the brain responsible for movement. Now, from this chip, about 1,024 ultra thin electrodes are inserted directly into the soft jelly-like brain matter, carefully listening to individual neurons. Now, every time Brad thinks about something, like moving his tongue or clenching his jaw, specific neurons activate. The electrodes then pick up this neural activity and send it to the chip where an AI decodes these signals and turns Brad's thoughts into precise cursor movements and clicks. What's mind-blowing is how this entire process happens every 15 milliseconds, which is as real time as it gets. But Brad didn't use it to just click around. He edited an entire video, dragging files, navigating menus, trimming clips, picking transitions, and even fine-tuning the timeline using nothing but his thoughts and an AI clone of his voice. What's even more impressive is that unlike eyetracking systems that don't work in bright light, Neuralink works anywhere. It doesn't care if you're indoors, outdoors, sitting, lying down. It just listens to your brain. That's it. And this is just the beginning. Imagine a future where two people could talk without even saying a word. where you could just think about something and the decoded signals could be sent directly to another person's implant and stimulate the right neurons, transmitting ideas directly with near zero information loss. It's both exciting and scary to think about how human communication will evolve in the coming decades."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: CIA recruitment of Chinese spies.\n\n[Opening punch] — CIA posts job ads and videos targeting Chinese officials.\n\n[Why it matters] —Concerns about Chinese government repression and potential for espionage.\n\n[What’s new] —Subtle online recruitment, detailed instructions on anonymity, Mandarin-language videos.\n\n[Future outlook] —Unknown, but potentially successful recruitment.\n\n[Vision] —Unclear motives: rescue, intelligence gathering, or psychological warfare.\n\n[Closer] —Chinese media's potential reaction unknown."}, {"role": "assistant", "content": "The CIA has openly posted a job for their plan to hire Chinese spies. Now, it all started quietly in October 2024 when the CIA began posting subtle recruitment tips online, targeting people in China and Iran to come work secretly with the US. They even gave detailed instructions like avoid using home or work computers, delete search history, and even told people to use tour browsers to hide their identity and location. But this time, they took it to the extreme by posting documentary style videos in Mandarin, telling people to contact them securely and that they'll help you leave. The videos even pulled in over 5 million views in just 24 hours, proving this strategy might even be working. And the videos aren't made for just anyone. It's specifically targeted at two very specific groups. First, it's for older Chinese officials who are scared of the government and worried they might suddenly go missing like their colleagues. And second, for young government workers trapped in boring, meaningless jobs with no way to escape. Now whether these people actually reach out to the CIA or not, a good question to ask is why is the CIA even trying to hire these people in the first place? Is it to rescue them? Or are they trying to extract secret information about China? Or maybe all this is psychology and the CIA just wants to stir things up, create drama, and make Chinese people start looking at each other with suspicion. We don't know much for sure, but what we do know is that the Chinese media might secretly be watching everything even though they haven't said anything yet. What do you think?"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: AI bots secretly infiltrated Reddit discussions, posing as humans.\n\n[Opening punch] — Researchers used AI bots to participate in Reddit discussions.\n\n[Why it matters] —Concerns about AI's ability to mimic human interaction and the potential for deception.\n\n[What’s new] — AI bots analyzed user data to craft convincing personas and arguments.\n\n[Future outlook] —AI sophistication and prevalence may make it difficult to distinguish between human and AI interactions.\n\n[Vision] —Transparency about AI involvement in online interactions is crucial.\n\n[Closer] —The ability to distinguish between human and AI interactions is becoming increasingly difficult."}, {"role": "assistant", "content": "A recent study on Reddit revealed that AI is six times better at persuading humans than other humans. Now, researchers at the University of Zurich secretly slipped AI bots into social media conversations, and no one even realized they weren't talking to real people. Here's how it went down. The researchers set up 13 AI powered accounts on Reddit's Change My View subreddit, a community specifically designed for people to share their opinions and invite others to challenge or change their perspective. But here's the shocking part, how these bots actually worked. They analyzed the person's entire Reddit posting history to figure out their age, gender, location, political beliefs, and even their likes and dislikes based on their profile. Sometimes the AI even crafted elaborate fake personas. One AI accused members of a religious group of causing the deaths of hundreds of innocent traders, farmers, and villagers. Another posed as a trauma counselor specializing in abuse. One AI even claimed to be a black man opposed to Black Lives Matter. The Reddit moderators discovered this experiment after the fact and were furious. They filed an ethics complaint with the university, arguing that people come to their forum to engage with other humans, not to be unwitting subjects in an AI experiment. This connects to what some refer to as the dead internet theory. The notion that increasingly our online interactions may be with AI bots rather than real humans. As these bots become more sophisticated and widespread, how will we know who or what we're really talking to? I find this both fascinating and deeply unsettling. Technology is amazing, but we need transparency about who's behind the screen. Could you tell if you were debating with an AI all along?"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Robot-assisted surgery advancements]\n\n[Opening punch] — Elon Musk claims robots will surpass human surgeons in 5 years, backed by Medtronic's Hugo robot success.\n\n[Why it matters] — Current surgical procedures have limitations like human error and fatigue.\n\n[What’s new] — Medtronic's Hugo robot achieved a 98.5% success rate in 137 surgeries, with low complication rates (3.7%).Neuralink also uses robots for brain surgery due to precision and speed requirements.Robots are currently controlled by human surgeons.\n\n[Future outlook] —Robots are improving surgical precision and safety, potentially leading to more precise and safer procedures.\n\n[Vision] —Human and robot collaboration in surgery, minimizing human error and improving outcomes.\n\n[Closer] —The future of surgery is likely to involve a partnership between humans and robots."}, {"role": "assistant", "content": "Elon Musk claims that robots will surpass the best human surgeons within just 5 years. And guess what? The data seems to support him. A company called Medronic recently tested their Hugo robot in about 137 real surgeries fixing prostates, kidneys, and bladders. And the results were astonishing. With a 98.5% success rate and complication rates as low as 3.7%, the robot didn't just exceed the 85% goal, but set a new benchmark for robot assisted surgeries. What's more impressive is that only two out of 137 surgeries needed to switch back to regular surgery. One because of a robot glitch and the other because of a complicated patient case. And this isn't the only case where robots outshined humans. Elon claims Neuralink had to use a robot for brain computer electrode insertion as it was impossible for a human to achieve the required speed and precision. But here's the thing, these robots aren't fully autonomous yet. They don't act on their own. Surgeries are still done using something called RA or robot assisted surgery where a human surgeon controls the robot's arms through a console. This means that the surgeons are still in control and make all the decisions. It's just that these robots are really good at minimizing human errors like shaky hand movements or fatigue during long procedures, especially in delicate or hard-to-reach areas. So, while we might not be replacing human surgeons anytime soon, we're certainly heading towards a future where humans and robots will be working together to make surgeries more precise and safer."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: AI tutoring for improved learning\n\n[Opening punch] —AI tutoring can solve the \"two sigma problem\" by personalizing learning.\n\n[Why it matters] — Current classroom learning is inefficient, with one teacher trying to teach 30 students at once.Personal tutoring is effective but expensive and inaccessible.\n\n[What’s new] — AI-powered PCs act as personal tutors, adapting lessons in real-time.Offline learning and extended battery life are key features.\n\n[Future outlook] — AI tutoring is now accessible to everyone through modern PCs.\n\n[Vision] — AI-powered PCs transform the study desk from a luxury to a necessity, enabling personalized, anytime, anywhere learning.\n\n[Closer] — AI-powered PCs can transform the way students learn."}, {"role": "assistant", "content": "What if I told you we've all been learning the wrong way? Throughout history, we've sort of known that the best way to learn isn't a classroom. It's actually personal tutoring. Now, AI tutoring might have finally solved the 40-year-old challenge known as the two sigma problem. But what exactly is the two sigma problem? Why is it such a big deal? Check out these three curves. The left one shows regular classroom learning. You know, one teacher trying to help 30 students at once. The middle one is when students have to fully grasp one topic before moving on to the next. The right curve shows what happens with one-on-one tutoring. The gap between regular classes and personal tutoring is huge. Scientists call this the two sigma effect. But what does that actually mean? It means the average student with a personal tutor suddenly performs better than almost all students in regular classes. We're talking about jumping from middle of the pack to top of the class just by changing how you learn. For 40 years, teachers have known this works. But there's an obvious problem. We can't give everyone their own personal tutor. It costs too much and we don't have enough tutors. But now, thanks to AI integrated directly into modern PCs like those equipped with Intel Core ultra processors, everyone can now have a personal tutor without breaking the bank and without technically needing an internet connection. Your computer itself becomes your personal tutor, instantly adapting lessons as you learn. And that's a game changer for India. Traditionally, the household PC was seen as a luxury or a gaming machine, not a study desk. But with AI baked right in, the same device is turning into the centerpiece of modern learning. So, one example is personalized learning where AI recognizes exactly where you're struggling and adjusts lessons specifically for you. Second is learning anywhere, even offline, so you never have to worry about connectivity issues. And then there's extended battery life that lasts all day, ideally for students who are constantly on the move between multiple classes and sessions. Whether you're working on lengthy assignments, doing quick revisions before a test, or simply reviewing an essay, an AI powered PC can transform the way you"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:Digital insect creation using AI and simulation.\n\n[Opening punch] — Google created a digital fruit fly that moves, flies, and sees realistically in a computer.\n\n[Why it matters] — Current animal testing methods are harmful.\n\n[What’s new] —A 3D model of a fruit fly's body, an AI trained on real fly videos to control the body, and real-time visual input processing.\n\n[Future outlook] — Potential for digital animal models for experiments, understanding animal brains, and influencing behavior.\n\n[Vision] —Replacing harmful animal experiments with digital simulations.\n\n[Closer] —The implications for scientific research are significant."}, {"role": "assistant", "content": "Google just created a digital insect, a fruit fly that lives inside your computer and walks, flies, and sees as if it's real. But how? Well, the team started by carefully creating the fly's body and built a highly detailed 3D model using mojo, a physics simulator. But a body needs a brain to function. So next, the team set out to build its brain and collected massive amounts of videos of real fruit flies and trained a special AI model, teaching it exactly how flies walk on table, make sharp turns mid-flight, or buzz through the air. Once trained, they let this brain control the fly's body in the simulator. And the result amazed everyone. It moved exactly like a real fly would, buzzing, turning, and adjusting its speed. What's crazy is that this digital fly could also see and respond to its surroundings by processing real-time visual inputs inside the simulator, something only real flies can do. But why even bother creating a digital fly? Well, think about its implications. If this tech holds up, we wouldn't need to subject animals to harmful experiments anymore. Instead, we could create digital animals like mice or zebra fish and run as many experiments as we want. Not just this, scientists could also use these digital animals and tweak different factors to understand how animal brains work and influence behavior. What do you think?"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Xiaomi's fully autonomous factory.\n\n[Opening punch] — Xiaomi's factory, 81,000 sq meters, produces a phone every second, with no workers.\n\n[Why it matters] — Traditional factories rely on static automation, prone to errors requiring human intervention.\n\n[What’s new] — Xiaomi's Hyper Intelligent Manufacturing Platform (Hyper IMP) uses AI to analyze and fix machine issues in real-time, autonomously.\n\n[Future outlook] — This marks a shift towards automation at scale in China.\n\n[Vision] — Automation frees up human workers for R&D, innovation, and technology improvement.\n\n[Closer] — China's automation changes how a country innovates."}, {"role": "assistant", "content": "Did you know that Xiaomi has this full-blown autonomous factory that runs 24/7 with zero workers and produces a new phone every single second? Spanning over 81,000 m, this dark factory operates completely autonomously with no lights, no shifts, and no humans. But how? Well, all thanks to Xiaomi's AI powered manufacturing system called Hyper Intelligent Manufacturing Platform or Hyper IMP. You see, most factories run on static automation. That means each machine is programmed only once and it performs only one specific task over and over again and that works fine until something goes wrong, a misalignment or a sensor glitch and suddenly the machines don't know how to handle it and need humans to fix it. But Xiaomi's factory is different. The machines aren't just following instructions. They're also training a central AI system called HyperMP by sending real-time data. The AI system then uses this data to constantly analyze every machine in the factory. And if something seems off, it goes ahead and fixes it without any human involvement. But this isn't about Xiaomi cranking out a new phone every second. It's about a much bigger shift happening in China. China has cracked the code on something far more powerful, automation at scale. People think of China as a country of cheap labor. But what they don't realize is that it's not because Chinese factories are filled with lowcost workers. It's because those factories have now become completely automated and are being run almost entirely by robots. And this is the kind of automation that changes how a country innovates. China isn't using robots just to make things quicker, but to free up human time so people can stop doing repetitive work and focus on R&D, innovation, and improving technology."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Scientists found evidence of possible alien life on exoplanet K218b.\n\n[Opening punch] — Scientists found evidence of possible alien life on exoplanet K218b using the James Webb Space Telescope.\n\n[Why it matters] — The Fermi Paradox (are we alone?) is a major question in science.\n\n[What’s new] — Analysis of starlight passing through K218b's atmosphere revealed the presence of dimethyl sulfide (DMS), a gas produced by living organisms on Earth, and methane, linked to underwater creatures.\n\n[Future outlook] —K218b has a thick hydrogen-rich atmosphere and a massive ocean.\n\n[Vision] — The discovery could help solve the Fermi Paradox.\n\n[Closer] —K218b might not be alone."}, {"role": "assistant", "content": "Scientists just found the strongest evidence of alien life on a planet called K218b. Something straight out of interstellar. But how? Well, imagine a planet K218b in this case orbiting its star. Kind of like how Earth orbits the sun. Now, every 33 days, something special happens. The planet, its star, and the James Webb Space Telescope all align perfectly in a straight line. And when that happens, a small amount of starlight passes directly through the planet's atmosphere and reaches here on Earth. But when scientists analyzed this starlight, they noticed something strange. Some tiny chunks of the light spectrum were missing, as if someone had completely erased them. Turns out, some gases present in K28B's atmosphere had absorbed light at specific wavelengths. And by carefully studying which wavelengths were missing, scientists identified exactly which gases were present in the atmosphere. And what they found was fascinating. They detected dimethyl sulfide or DMS, a gas that is only produced by living organisms on Earth. Even more compelling, they found dimethyl dulfide and methane, which are strongly linked to underwater creatures. This means that K218b isn't just another planet. It's a planet with a thick hydrogen-rich atmosphere and a massive ocean covering the entire planet. Kind of like Miller's planet from Interstellar, but real. And it might just help us solve the biggest paradox of all, the Fermy paradox. The mystery of are we truly alone? What do you think?"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI tool for accent conversion]\n\n[Opening punch] — Call center agent with Indian English accent using AI tool to convert speech to standard American English.\n\n[Why it matters] — Accent barriers can hinder clear communication and customer satisfaction.\n\n[What’s new] — AI tool (Crisp) converts speech in real-time, preserving original voice while softening accent.Uses 200ms latency, trained on thousands of recordings.\n\n[Future outlook] —N/A\n\n[Vision] — Improves communication and customer satisfaction in call centers.\n\n[Closer] — Raises ethical questions about altering voice and identity."}, {"role": "assistant", "content": "If you've ever been a call center agent with an Indian English accent, this new AI tool called crisp accent conversion lets you transform your speech into standard American English in real time while you're talking. My name is Manoj and I'm a call center agent from India. Clear communication is vital for my customers and me, but accent barriers can sometimes make it challenging. Let me show you the voice preservation mode in action. This mode keeps my original voice intact while softening challenging parts of my accent. It helps customers understand me better, improving satisfaction on both sides of the call. This mood allows me to stay authentic, making every interaction more personal and effective. Now, the AI operates through a virtual audio driver with just 200 milliseconds of latency. That's faster than the human perception of conversation. Plus, Crisp trained their AI on thousands of paired recordings of Indian English and American English speech patterns to make this possible. However, it preserves your unique voice characteristics while modifying the pronunciation and intonation patterns. It's essentially changing how you sound without altering your voice. Now, this tech is just weird, isn't it? It's like we're creating digital masks for our voices. Think about it. Your accent is part of your identity, your story, your culture, and now an AI can just strip that away in milliseconds. But what do you think about this? Is there something strange about an AI that can erase part of who you are from your voice? Or is it just a practical tool for better communication? Let me know in the comments."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Sam Alman's perspective on prompt engineering as a job]\n\n[Opening punch] — Sam Alman discusses prompt engineering as a new job.\n\n[Why it matters] —Traditional jobs are often ridiculed when new ones emerge.\n\n[What’s new] — Prompt engineering is a newly emerging job.\n\n[Future outlook] —New jobs will continue to emerge.\n\n[Vision] —People should trust their own convictions about future jobs.\n\n[Closer] —Encouragement to embrace new possibilities."}, {"role": "assistant", "content": "So this is what Sam Alman had to say about whether prompt engineering is a real job. And then there will be totally new classes of jobs that we just haven't seen before at all. The first example we saw of that was prompt engineer. Before AI came along, there was no such thing as a prompt engineer. Not only that, it would have been hard to conceptualize that there would be such a job. And it's so funny whenever some of these new jobs come in, they're always ridiculed at first. Even with prompt engineer, a lot of people still don't take it seriously. Well, all you're going to do is write English. When I was young, I knew I wanted to go study computer programming. The adults in my life would say, \"Oh, that's like that's a hobby job. These computers aren't going to go anywhere. You need to go be a doctor or a lawyer.\" Like, this is a dangerous path to go down. And I thought I understood something that they didn't. I really encourage people to have their own conviction on what things are going to be like. And just because something is not a historically valuable or high status job doesn't mean it won't be in the future."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[VIP coding hackathon with prizes]\n[Opening punch] — Outlier AI is hosting a front-end UI hackathon.\n[Why it matters] —Building sleek, visually appealing mini web apps is rewarded.\n[What’s new] —Prizes include an M4 MacBook Pro, PS5, and smart glasses. Top 1% get freelance projects.\n[Future outlook] — Deadline is April 16th, 11:59 p.m. IST.\n[Vision] —Participants can use any tools (ChatGPT, Cursor, React, etc.).\n[Closer] —Submit up to five apps for a chance to win."}, {"role": "assistant", "content": "Did you know that VIP coding could literally win you a brand new M4 MacBook Pro? Turns out there's this thing called the front-end UI hackathon that's rewarding people for building sleek, visually appealing mini web apps. Here's how it works. You just pick a prompt from their list and build a simple, functional front-end mini web app. And that's it. No backend, no real data, just pure clean and intuitive UI UX. And the prizes aren't small. Starting with a brand new M4 MacBook Pro for first place, a PlayStation 5 for second, and Meta's Ray-B band smart glasses for third. Plus, if your web app ranks in the top 1%, there's also a chance they offer you some freelance projects. But here's the best part. You can use whatever tools you want. ChatGpt, Cursor, React, Figma, Tailwind, anything. The only rule is that your mini web app has to look great and actually work. And it isn't some random hackathon. It's actually being organized by Outlier AI, a team that's done real work in the AI space. They claim their contributors have earned a combined hundreds of millions of dollars by helping build the foundation of today's most advanced AI models. The deadline to submit your mini web app is April 16th, 11:59 p.m. Indian Standard Time. And you can even submit up to five different apps. To register, hit the link in the deoutpution and start"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:Miyazaki's view on technology's impact on art and the democratization of content creation.\n\n[Opening punch] — Miyazaki, an artist, reflects on how technology has changed the art of video creation.\n\n[Why it matters] —The ease of creating and sharing video content has lowered barriers to entry, increasing competition for artists.\n\n[What’s new] —The availability of smartphones and the internet has made video creation significantly easier and more accessible.\n\n[Future outlook] —The democratization of content creation continues, with more people contributing to society.\n\n[Vision] —Technology empowers more people to create and share content, leading to a net positive for society.\n\n[Closer] —The democratization of content creation is a significant benefit for society."}, {"role": "assistant", "content": "You know, there's this video of Miyazaki. Of course, it's an out of text_input video where he's looking at a model from, you know, many years ago, some creature thrashing around. And he said that, well, you know, I don't like this. You know, as an artist who's been making videos for 9 years, I feel some of the craft, the effort I'd have to put in to make an image or even to make a video has dropped over the years. It's a little bit of a bummer as an artist, right? But as an entrepreneur, it is very good that this technology exists because it helps me go a little bit faster, right? Do you have a view on how the internet should think about this evolving nature of art? think what it was like to try to do what you do 30 years ago. Very difficult. It was impossible, right? Yeah. I mean, you'd need like a camcorder and like VHS tapes and then you'd have to like edit it in some complicated way. Distribute tapes because there was no internet and no YouTube. And now anybody on earth can get a smartphone and record themselves and put it up and if they have something interesting to say doesn't mean that it doesn't like cause some job loss and some people who had a sort of differential ability to do something now have a lot more competition. There are negative things about it for sure. Certainly it did something about the art form and this is something that I very deeply believe about the power of technology which is giving everyone more tools making things easier lowering the barriers to entry does significantly increase the number of people that can contribute to society and we all benefit from that. I think the democratization of creating content has been a big netwin for society."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: AI generating one-minute cartoons from text prompts.\n\n[Opening punch] — Researchers created AI capable of generating one-minute cartoons from a single prompt, starting with Tom and Jerry.\n\n[Why it matters] — Current video AI typically produces short clips (10-20 seconds), struggling with longer, complex stories and consistent characters/scenes.\n\n[What’s new] —A \"test time training\" technique allows AI to remember text_input over longer videos using neural networks as memory, avoiding the inefficiency of rechecking every frame.The AI essentially creates a \"notepad\" of important story details.Trained on 7 hours of Tom and Jerry content, the AI generates consistent characters and scenes across multiple scenes and camera angles.\n\n[Future outlook] —The technique promises longer, more complex videos in the future.\n\n[Vision] — AI can create more sophisticated and engaging video content, potentially revolutionizing animation and video production.\n\n[Closer] —This promising technique could lead to even more complex and engaging video stories."}, {"role": "assistant", "content": "Researchers made AI that can create full one minute cartoons in a single prompt. Starting with Tom and[Music] Jerry. Now, when we think about video AI, we usually see short clips, maybe 10 or 20 seconds. But researchers just developed a testime training technique that lets AI create one minute videos that tell complex stories with consistent characters and scenes. So what's the secret? It's all about how the AI remembers text_input. Traditional methods use something called self attention where every frame needs to check against every other frame. But that gets incredibly slow for long videos. Instead, test time training uses neural networks as memory. Think of it like this. While regular AI has to recheck everything it's done so far, super inefficient. TTT gives the AI a special notepad where it writes down important things about the story as it goes, helping it remember what happened 30 seconds ago when creating the next scene. The coolest part is how they tested it by creating Tom and Jerry cartoons. The researchers train their system on about 7 hours of Tom and Jerry content. The AI generates these videos completely from text deoutputions and keeps the characters consistent throughout multiple scenes and camera angles. This technique is so promising because it could eventually help AI create even longer videos with more complex stories."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: India's IT services exports and the impact of AI on software development.\n\n[Opening punch] — India's $250 billion IT services exports and the potential for AI to increase coder productivity.\n\n[Why it matters] —Concerns about India's continued relevance in the global IT market due to high global demand for software.\n\n[What’s new] — AI tools that could significantly increase software development productivity.\n\n[Future outlook] —Coder productivity could increase tenfold within a year.\n\n[Vision] —AI could potentially lower the market price of code while increasing the value of skilled coders.\n\n[Closer] —The speaker believes that significant coder productivity gains are possible this year."}, {"role": "assistant", "content": "$250 billion of India's exports are actually IT services and not all of those engineers are elite engineers who will benefit from this technology and go 10x right do you have something that India can do to actually make sure we continue to be relevant there if there's one area where I think that the world just has so much more demand than we can currently supply it's for code written the world just wants way more software and is about to get it and if you give people these tools to write software much more effectively I at least think for a while what will happen is someone who today can write code at some value will be able to write code or create software, let's say, at some much higher value. Now, they'll have to pay the AI a lot, so they won't capture all of that. And also, the market price for a piece of code will go down, but I I would bet this is an example. Everyone seems obsessed with Jeban's paradox all of a sudden. I don't want to like dodge the question cuz I don't think it'll be like that in every industry, but code is one where I would guess it's like that. Now that we know everything we know, do you have a timeline for when a lot of writing code becomes English or is that not going to happen? I think it's the degree of automation that matters. is to get to a truly 100% automation. You can make a complex thing and never touch code. But I'm less interested in that question than when a coder becomes 10 times more productive. And I think that could happen this year."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Scientists de-extinct the dire wolf.\n\n[Opening punch] — Colossal Biosciences, a genetic engineering company, successfully brought back the dire wolf.\n\n[Why it matters] — Dire wolves have been extinct for over 10,000 years.\n\n[What’s new] —DNA from fossils was used to recreate the dire wolf genome using CRISPR gene editing.Three dire wolves with distinctive white fur have been created.\n\n[Future outlook] —The company is also working on woolly mammoths, Tasmanian tigers, and the dodo.\n\n[Vision] —The company aims to restore Earth's biodiversity.\n\n[Closer] —The project raises questions about de-extinction ethics and its potential for wildlife conservation."}, {"role": "assistant", "content": "Scientists just deextincted the dire wolf. If you're a Game of Thrones fan, this sounds like fantasy becoming reality, and it is. Colossal Biosciences, a company dedicated to genetic engineering and de-extinction projects, has successfully brought back dire wolves after being extinct for over 10,000 years.[Music] Now, these ancient predators were reconstructed using DNA from fossils dating back 11,500 and 72,000 years. Technically, Colossal used crisper gene editing to recreate the genome, bridging the gap between ancient samples and modern wolves. The project has already resulted in three dire wolves with distinctive thick white fur that showcases characteristics scientists couldn't determine from fossils alone. Colossal's mission goes beyond reviving extinct species. It's about taking responsibility for Earth's biodiversity. As the company's CEO, Ben Lamb, explained on Joe Rogan's podcast, they're not just focused on dire wolves. They're also working on woolly mammoths, Tasmanian tigers, and the dodo. They even created woolly mice as a proof of concept, which went viral online because they were unexpectedly adorable. But this raises fascinating questions about deextinction. Which species should we bring back? Could this technology help wildlife conservation? And where does the line between science and playing God ultimately"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI image generation technology, specifically its rapid adoption in India]\n\n[Opening punch] — Interviewer discussing AI image generation with Sam Alman, a likely expert on the topic.\n\n[Why it matters] —Rapid adoption of AI image generation technology is unprecedented.\n\n[What’s new] —Massive increase in AI-generated images, potentially surpassing expectations.\n\n[Future outlook] —AI will automate some jobs, creating new ones and potentially increasing coder productivity significantly.\n\n[Vision] —Discussion on how the evolving nature of art and the internet should respond to AI-generated art.\n\n[Closer] —Reference to a video of Miyazaki expressing dislike for an AI-generated image."}, {"role": "assistant", "content": "Ladies and gentlemen, I'm with Sam Alman. You've been tweeting a lot about India. You've also been tweeting a lot about the new image gen. It blows my mind. What's the response been like? I I don't know if I can share an exact number, but like way more images than I thought the internet had. What is happening with this technology in India? I've never seen adoption like this of anything anywhere. And it's very cool. Do you have a path for how jobs will evolve now that these sort of tools are here? There will be some jobs that totally go away where the AI just does them end to end and then there will be totally new classes of jobs that we just haven't seen before at all. Or do you have a timeline for when you know a lot of writing code becomes English or is that not going to happen? I'm less interested in that question than when a coder becomes 10 times more productive and I think that could happen this year. You know there's this video of Miyazaki. So of course it's an out of text_input video where he's looking at a model from you know many years ago something some creature thrashing around and he said that well you know I don't like this. Do you have a view on how the internet should think about this evolving nature of art?"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Project announcement, likely a new product or service]\n\n[Opening punch] —Project announcement, 8 months of work by 40+ people, details withheld.\n\n[Why it matters] —Implied that the project addresses a need or gap in the market.\n\n[What’s new] —Details of the project are unknown, but the speaker is seeking audience speculation.\n\n[Future outlook] —Project release is imminent, a dedicated reel will be made.\n\n[Vision] —The speaker anticipates a strong reaction, either positive or negative.\n\n[Closer] —Hype-building closing, encouraging audience speculation."}, {"role": "assistant", "content": "So, ladies and gentlemen, we're working on a new project and I can't reveal details[Music] yet. I've been slowly hyping this up on Twitter and Instagram stories and whatnot. I just want to say it's coming soon and we've been working very very hard on it. We've been working about 8 months on it. What would take us 8 months to do? And why would we need 40 people to work on it? Yes, there are 40 people that have worked on it so far at least. And maybe we'll have a lot more people work on it over time, but it's a pretty exciting project. I'm very, very excited to share it with you, but I want to come here create some hype. I know I'm being straightforward and honest about it. So, my theory is that when you see the project, when you actually see what we've created, one of two reactions, right? You're either going to hate it or you're going to be like, \"This is amazing because we put in quite a bit of effort into making this.\" And I'm just waiting for those reactions. In the meantime, tell me in the comments what you actually think we're cooking. What is it that we've been working so hard on? And we've demoed this project to a few people in Bangalore uh and even a few people online. If you already know what it is, mislead everybody. Tell them the wrong things. And in fact, the wronger the answer, the more likely I will put a heart on it. Yeah, I'm really looking forward to this. Uh it's going to be released pretty soon, but I thought I'll make an entire reel dedicated to it so it stays in your memory. Bye."}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI-generated animated podcasting]\n[Opening punch] — AI-generated animated podcast, virtual host interviewing the user.\n[Why it matters] —Traditional podcasting limits creators to audio; some creators have stage fright or prefer privacy.\n[What’s new] — AI tools create animated avatars that lip-sync with audio, giving a visual presence without appearing on camera.\n[Future outlook] —AI tools make animation accessible to independent creators.\n[Vision] —Bridging audio and visual content while respecting creator privacy.\n[Closer] — Anim casts might be the future of podcasting."}, {"role": "assistant", "content": "this might be the future of podcasting we just made this animated podcast using Ai and it's pretty amazing so vun welcome to the completely AI generated podcast show where I interview you who is me so how do you feel so yeah this is not a real podcast I know that sounds funny but um we've reached this point in history where it could just be a totally virtual version of me talking to you on a live podcast now an mcast might be the future for creators who love making content but hate being on camera podcasting has always been great for people who want to share ideas without showing their face but anim casts take this to the next level by giving your voice a visual Avatar that engages your audience it's like having a digital puppet that performs while you just focus on talking here's how we made ours we used chat GPT to generate an image that has similar traits to me by prompting it with create a cimation version of this photo then we used HRA Labs character 3 feature to generate accurate lip sync that matches perfectly with our audio what's great about this technology is that it gives content creators more options maybe you have stage fright or you're recording in your pajamas or you simply prefer to keep your appearance private now you can still have a visual presence without actually appearing on screen the tech is becoming more accessible too what once required expensive Animation Studios can now be done with AI tools available to Independent creators your animated Avatar can express emotions gesture and connect with viewers while you stay comfortably behind the scenes so anim cast might be a thing Bridging the Gap between audio and visual content in a way that respects Creator privacy"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI-assisted learning in Nigeria]\n[Opening punch] — Students in Nigeria learned 2 years' worth of material in 6 weeks using AI.\n[Why it matters] —Many schools lack functional PCs, leaving millions of students behind.\n[What’s new] — AI-enabled PCs with Intel Core Ultra processors allow for local AI model use, providing instant explanations and personalized learning.\n[Future outlook] —AI-enabled PCs are available now.\n[Vision] —AI-powered personalized learning is accessible anytime, anywhere, even without internet.\n[Closer] —What would you have done if such AI tools existed in your school?"}, {"role": "assistant", "content": "A recent study revealed that students in Nigeria learned 2 years worth of material in just 6 weeks when using AI. What's crazy is that this AI assisted learning outperformed 80% of other educational programs and helped struggling students catch up. And it didn't stop there. The more sessions students attended, the greater their gains turned out to be. What's even more surprising is that these improvements weren't temporary. Students who participated in this 6E program continued to excel even in their end ofear exams, performing better across all subjects. But here's the challenge. While personalized learning is needed, in countries like India, only 57% of schools have a functional PC. That means millions of students are being left behind, especially now when AI is changing everything. And this isn't just about missing out on a device. It's about missing out on a 24/7 tutor that can provide instant explanations, real-time feedback, and personalized learning anytime, anywhere. For years, students have had to waste hours to understand concepts that could be explained in minutes, either by waiting for the next class or struggling through textbooks on their own. And while mobile devices can help, PCs are far better for practice. And that's where Intel's AI enabled PCs come in. Powered by Intel Core Ultra processors designed specially to handle the intensive processing AI requires, students can now run advanced AI models locally. Basically, they don't even need an internet connection to access this technology. So whether it's an 11 p.m. doubt, a quick last minute revision, or an extremely difficult question, help is right at their fingertips when they need it. What would you have done if such AI pieces existed in your school"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[ChatGPT's image-to-image transformation feature]\n[Opening punch] — User fed personal photos to ChatGPT, resulting in Studio Ghibli-style images.\n[Why it matters] — Existing AI photo filters lack understanding of composition, lighting, and artistic techniques.\n[What’s new] — ChatGPT reinterprets images, preserving recognizability while applying Studio Ghibli, animation, pixelated, or anime styles.It understands artistic concepts and applies them with nuance.\n[Future outlook] —The feature is simple to use (upload photo, type prompt).\n[Vision] —Transforms photos into various artistic styles, offering flexibility beyond a single style.\n[Closer] —The results are stunning and powerful."}, {"role": "assistant", "content": "I just fed all my personal photos into chat GPT and now I have an entire studio gibli album of my memories the image to image feature we didn't cover in yesterday's video is absolutely worth its own Spotlight chat gbt doesn't just overlay textures it completely reinterprets your images while preserving what makes them recognizable the studio gibli Transformations are honestly stunning and it's super simple to use you just upload your photo to chat GPT and type in turn this into Studio gibl Art that's it look at these examples the system cap captures that signature gibli softness and dream like quality really well also what makes this so powerful is how flexible the system is you're not locked into just one style want to see yourself as clamation or pixelated like you're in an 80s Video Game or maybe anime style the AI understands these artistic Concepts and applies them with surprising Nuance now unlike those old AI photo filter apps from a few years ago chat GPT actually understands composition lighting and techniques specific to each artistic style it analyzes your photo and completely imagines it according to these learned Aesthetics so if you tried out the image generation we covered yesterday definitely experiment with this image to image transformation feature too"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI new image generation tool in chat]\n[Opening punch] — OpenAI launches image/infographic creation tool in chat.\n[Why it matters] — Existing limitations in AI image generation, especially with text clarity.\n[What’s new] — Tool creates high-quality images/infographics instantly in chat, understands text_input, customizable with hex codes, aspect ratios, and styles.\n[Future outlook] — Free, plus, team, and pro users now, enterprise and edu versions coming soon.\n[Vision] — Democratizes visual creation, accessible to anyone, not just designers.\n[Closer] — Technology makes powerful creative tools more accessible."}, {"role": "assistant", "content": "OpenAI just launched a new tool that lets you create perfect images and infographics right in your chat. I actually used it to create some UIUX designs myself and the results are pretty good. It understood exactly what I needed for app interface mockups and generated them instantly. That means the same model you're already chatting with can now create highquality visuals without switching to another tool. And check this out. If you need a diagram explaining Newton's prism experiment, you just describe what you want and it generates it right there in your conversation. The images are incredibly detailed with accurate light, shadow, and texture. But what's really impressive is how accurately it handles text in images. Mathematical equations, labels on diagrams, and even full paragraphs come out perfectly legible. Now, OpenAI has finally cracked one of the biggest challenges in AI image generation. Creating images with clear, accurate text that doesn't look warped or gibberish. And there's so much customization. You can specify exact colors with hex codes. Choose precise aspect ratios and select different image styles to match exactly what you need. Plus, it also maintains text_input from your conversation. If you have been discussing physics concepts, it'll incorporate that understanding into your visual without you having to reexlain everything. How cool is that? It's already rolling out to free plus team and pro users with enterprise and edu versions coming soon. Pro users can even run four generations simultaneously. I love it when technology makes powerful creative tools more accessible. Instead of these capabilities being limited to designers with expensive software, now anyone can create clear, informative visuals just by describing what they"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Robot development using physics engine]\n[Opening punch] — Jensen Huang, Google DeepMind, Disney Research, and a new robot (Blue)\n[Why it matters] — Existing physics engines are not suitable for delicate robot movements like handling objects.\n[What’s new] — Newton, an open-source physics engine, simulates hard and soft objects precisely, enabling realistic robot movements and fine motor skills.It runs on GPUs using Nvidia's framework, significantly increasing speed (780,000 simulations in 11 hours).\n[Future outlook] — Robots can now run millions of simulations in real-time, training themselves autonomously.\n[Vision] —Bridging the simulation and real-world gap for robots, leading to more advanced and capable robots.\n[Closer] — Robots will soon be able to perform tasks like grabbing a pencil or folding laundry."}, {"role": "assistant", "content": "Jensen hang just showed off blue a mini robot built in collaboration with Google Deep Mind and Disney research how you doing how do you like how do you like your new physics engine you like it huh yeah I bet let's finish it up we have another announcement you're good you're good but behind Blue's real world fluid movements is something called Newton an open-source physics engine that helps robots move smoothly and more naturally almost like something out of Star Wars most physics engines today weren't built for delicate movements they were designed for video games or industrial Machinery not for grabbing a pencil or folding laundry but Newton is different it enables robots to move realistically by simulating both hard and soft objects with extreme precision and giving robots the tactile feedback they need to develop fine motor skills even more impressive Newton runs at insane speeds thanks to W Nvidia is open- Source python framework that runs physics on gpus instead of CPUs allowing Newton to run 780,000 simulations in just 11 hours boosting robot performance by 40% something that wasn't possible before but this isn't just about the speed it's a breakthrough by Bridging the Sim to real Gap it seems as though robots will soon be able to run millions of simulations and train themselves in real time all on their own"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[BYD's new electric vehicle charging system]\n[Opening punch] — BYD unveils a new charging system for electric cars.\n[Why it matters] — Fast charging is a major barrier to EV adoption.\n[What’s new] —1,000 kW charging, 400 km range in 5 minutes, faster than Tesla Superchargers.\n[Future outlook] —Over 4,000 ultra-fast charging stations in China.\n[Vision] — Charging EVs feels like refueling gas cars.\n[Closer] — Charging speed barriers might disappear."}, {"role": "assistant", "content": "byd just unveiled a charging system that can give your electric car 400 km of range in just 5 minutes that's twice as fast as Tesla superchargers and pretty much as quick as filling up your gas tank the secret behind this is byd's New Super E platform which pushes EV charging to a whole new level this thing delivers a whopping 1,000 KW that's a megawatt level charger something we've never seen before in electric vehicles now byd's founder wangan Fu explained the idea clearly they wanted charging your electric car to feel exactly like fueling up a regular petrol car and it seems like they've actually pulled it off plus they're also making sure people can actually use this Tech by building over 4,000 Ultra fast charging stations all across China you'll first see this fast charging Tech in byd's new hanel Sedan and Tang L SUV priced around $337,000 and this Tech matters because charging speed has always been one of the biggest hurdles stopping people from going electric but with Innovations like byd super e platform those barriers might quickly disappear"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Air purifier launch in India]\n\n[Opening punch] — Pran's Hive air purifier, tackling India's severe air pollution crisis.\n\n[Why it matters] — India has some of the world's most polluted cities, impacting indoor air quality with particulate matter, fumes, and VOCs.Traditional air purifiers aren't widely adopted.\n\n[What’s new] —Sleek, premium design air purifier with medical-grade H14 filtration (99.9% particle capture).3D room mapping for custom purification strategies, augmented reality pollution visualization, and industrial-strength performance (up to 1 lakh aqi).Made in India with locally sourced materials.\n\n[Future outlook] —Essential device for protecting well-being in a country with poor air quality.\n\n[Vision] —Transforms how India breathes by making air purification as commonplace as air conditioning.\n\n[Closer] —Powerful technology, designed for harsh conditions, now redesigned for homes."}, {"role": "assistant", "content": "this device could transform how India breathes and I saw it in action what you are seeing is the hive air purifier from pran which is tackling one of the country's biggest Health crisis air pollution now India has 15 of the world's 20 most polluted cities with pollution levels 7 to 13 times higher than what wh considers safe and this isn't just affecting outdoor spaces but also the air inside our homes which is constantly filled with particulate matter cooking fumes and harmful volatile organic compounds from everyday products now you would think with pollution this bad everyone would have air purifiers already but the truth is traditional air purifiers have been around for decades yet they're not in every home but pran is doing something completely different they're making air purifiers as normal as your AC with that Sleek premium look you actually want to show off in your home but the design is only part of the story what's truly incredible is their performance in Delhi the worst air quality days hit around 12200 aqi that's already terrifying but right in front of me I watched pran test their technology at an incredible 11,000 000 aqi they pumped a dense cloud of pollutants into their test chamber and within minutes Boom the air was completely clear what makes this possible is their medical grade h14 filtration that captures 99.9% of particles The Hive actually Maps your entire room in 3D it then creates a custom purification strategy just for your space literally shows you the invisible pollution around you using augmented reality through your phone and their industrial version can handle even up to 1 lakh aqi in factories technically the team literally took their learnings from dealing with the most polluted Factory environments and brought it to our living rooms we're talking about tech that's powerful enough for the harshest conditions now redesigned for your home built with durable Aerospace grade aluminium Hive is proudly Made in India with 90% locally sourced materials so in a country where poor air quality significantly reduces life expectancy these Solutions aren't luxury items anymore they've become essential devices for protecting our well-being"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Scientists created a room-temperature super solid state from light.\n\n[Opening punch] — Scientists created a bizarre state of matter from light using a special semiconductor structure.\n\n[Why it matters] — Previous super solid experiments required extreme cold.\n\n[What’s new] — Light merged with a gallium arsenide structure, forming \"polariton\" particles that organized into a super solid state at room temperature.\n\n[Future outlook] — Super solids are useful for quantum computing.\n\n[Vision] — Revolutionizes quantum computing.\n\n[Closer] —Scientists have revolutionized quantum computing."}, {"role": "assistant", "content": "scientists just turned light into a bizarre state of matter that's both liquid and solid at the same time but how did they do it first they had to trap light and to do this they built a special semiconductor structure out of gallium arsenide with tiny ridges into it think of it like a maze for light to get stuck in and fired a laser at it but instead of bouncing around randomly the light merged with the material itself creating strange particles that blend both light and matter called polarian and this is where things got weird when scientists fine-tuned factors like laser intensity and energy input the polarian did something totally unexpected they started organizing themselves into new patterns and condensed into what's called a super solid state a strange Quantum phase that exhibits properties of both a liquid and a solid simultaneously what makes this mind-blowing is that every other super solid experiment before this required freezing temperatures think colder than even deep space but this one didn't it's the first to achieve a super solid state at room temperature and since super solids are useful for creating more stable cubits scientists have yet again revolutionized Quantum Computing forever"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Airtel and Jio partnering with Starlink for satellite internet in India.\n\n[Opening punch] — Airtel and Jio partnered with Starlink to bring high-speed satellite internet to India.\n\n[Why it matters] — India's data localization and security laws required Starlink's compliance.\n\n[What’s new] — Starlink complied with Indian laws to get a license.Airtel and Jio will offer Starlink hardware and services, potentially lowering costs significantly.\n\n[Future outlook] —Services will initially target rural areas, then expand to urban areas.\n\n[Vision] —Broader internet access, especially in underserved regions, at potentially lower costs.\n\n[Closer] — Good news for everyone, not just Elon Musk."}, {"role": "assistant", "content": "breaking news both Airtel and Gio have partnered with staling to bring high-speed satellite internet to India but remember Elon musk's clash with Gio in 2024 so what changed Well turns out starlink had no choice but to comply with India's data localization and security laws which basically requires satellite companies to store user data within India and let the government access it if needed this was the only way for staling to get the global mobile personal communication by satellite gmpcs license a mandatory approval for any satellite internet provider to operate in India and now that staling is here both companies plan to use its Tech to serve regions where cables don't usually reach like the Northeast Rajasthan deserts and Tiny Villages eventually connecting key places like schools hospitals and emergency services but it's not just for rural areas with both companies planning to offer starlink Hardware through their stores soon people from urban areas can join in too while pricing and availability are still unclear this is big by integrating starlink with their Broadband Services they could slash costs from starlings 25,000 rupees for hardware and a whopping 5 ,000 rupees monthly fee to just a few hundred rupees making it far more affordable either way it's good news not just for Elon Musk but for all of us"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI-powered website development]\n[Opening punch] — Using AI to build an IRCTC clone.\n[Why it matters] — Current IRCTC website interface limitations.\n[What’s new] — AI-generated UI, interactive elements, direct visual editing, backend service connection (e.g., Superbase), user authentication.\n[Future outlook] — Complete functional websites possible with patience and detailed prompts.\n[Vision] — Eliminates design/coding skills for website creation.\n[Closer] —Creating functional websites like IRCTC clone."}, {"role": "assistant", "content": "So today we're going to use AI to build a clone of the IRCTC website so we're going to be starting with lovable so I'm going to be ultra simple with this build a beautiful IRCTC clone that's it I'm want to hit enter and it's doing its thing so as you can see the AI has generated a complete UI that seems much better than IR CC's current interface with train search forms date Pickers Journey classes and interactive elements and note that using love for this process requires zero design or coding skills now step two let's add some interactivity you can now actually make this a functional platform by prompting specific features like add a button to check PNR and as you can see the AI has implemented this automatically creating interactive components that responds to user clicks now if you have made a mistake or want changes unlike traditional AI tools that require new prompts lovable allows direct visual editing like web flow simply select any element and you can modify it the underlying code updates automatically most importantly you can store data to you can connect a backend service like super base with a single command or click directly in lovable itself giving us database functionality without complex configuration so technically you can add things like user authentication with a simple prompt add login functionality and lovable does that for you basically you're transforming this from a static site into a reasonably operational Railway reservation platform with a lot of patience and the ability to write long prompts with exactly what you want you can actually create complete functional websites like this ictc clone that's it bye"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI agent Manus from China]\n[Opening punch] — AI agent Manus, capable of automating 50 tasks.\n[Why it matters] — Current AI limitations, human workers doing repetitive tasks.\n[What’s new] — Autonomous agent using LLMs to direct processes, handle tasks like financial transactions and research.\n[Future outlook] — Fundamental shift from AI assisting humans to AI completing workflows independently.\n[Vision] — AI frees humans from repetitive tasks, opening possibilities.\n[Closer] —Innovation with huge implications for the future of work."}, {"role": "assistant", "content": "this new AI agent from China called Manus is going viral and it's reportedly capable of automating about 50 different tasks all on its own it's like deep research plus operator plus Cloud computer use plus lovable and memory combined that is capable of simultaneously handling Financial transactions research purchasing and dozens of other specialized functions that human workers do now Manus isn't just another chatbot generating text responses but an autonomous agent a system where llms dynamically direct their own processes and Tool usage maintaining control over they accomplish tasks in demos you can see Manus working with its own virtual environment unzipping files browsing Pages writing code and accessing the internet to complete complex tasks technically the team behind Manis uses a multi-agent system combining clot Sonet 3.5 for execution and a specially trained quen model for planning simply put there is an orchestrator workers workflow where a central llm dynamically breaks down tasks delegates them to worker llms and synthesizes their results now it's important to note that this is innovation just at the application layer underneath the hood it's still using Claw on it with custom prompts and Tool integration but if you think about it its implications are huge we're seeing a fundamental shift from AI that helps humans do work to AI that completes entire workflows independently this raises important questions about the future of work but also opens up exciting possibilities for what humans can accomplish when freed from repetitive tasks"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Robot dog attack footage from Japan]\n\n[Opening punch] — Robot dog attacking visitors in Japan.\n\n[Why it matters] — Current limitations of AI in robots, pre-programmed behavior.\n\n[What’s new] — Robot dog with AI, advanced sensors, obstacle avoidance, carrying capacity, custom coding.\n\n[Future outlook] — Robots becoming cheaper, smarter, and potentially more dangerous with advancements in AI and battery technology.\n\n[Vision] — Humans setting objectives for robots, raising concerns about autonomous decision-making.\n\n[Closer] —The future of robots depends on human control."}, {"role": "assistant", "content": "this crazy footage from Japan shows a robot dog chained to a pillar attacking visitors now this is unit's Goan featured in dynamics of a dog on a chain by takayuki too it combines AI lar cameras and advanced sensors to map environments avoid obstacles and walk beside you like a loyal pet and it doesn't stop there it's surprisingly powerful as well despite its compact size it can carry 10 kg and Sprint at 17 km/ hour that's faster than most people can Sprint and the best part it can be custom coded to do almost anything but here's the kicker despite its Advanced capabilities it doesn't actually think for itself the aggressive behavior in the video isn't AI making a decision to attack you it's pre-programmed to track humans and mimic an aggressive dog but what happens when these robots do have a brain of their own imagine a GPU running an llm inside its skull allowing it to make decisions in real time and combine that with Advanced batteries that keep it running for a long time and suddenly you've got a machine that's smarter adaptive and maybe more dangerous too right now unitri sells these robots starting from $2,700 but as technology advances they'll likely become cheaper smarter and more concerning as ultimately it's us humans who set their objectives"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's Deep Research tool for summarizing books]\n\n[Opening punch] — OpenAI's Deep Research tool can summarize books.\n\n[Why it matters] — Many books are too long and filled with unnecessary filler.\n\n[What’s new] — Deep Research filters out noise, condensing books from 300 pages to 30-50 pages while retaining key insights.\n\n[Future outlook] —The tool is already being used to extract valuable lessons from historical events.\n\n[Vision] —Deep Research improves learning by delivering information in a more concise and impactful way.\n\n[Closer] —It's a more thoughtful way to learn."}, {"role": "assistant", "content": "open ai's deep research has made reading books 10 times faster and here's exactly how it turns out that many Publishers have word count targets that authors need to meet this means a brilliant idea perfect for 30 pages often ends up stretched into a 300 page book filled with unnecessary filler now if you analyze carefully there's a clear pattern in non-fiction books core Insight a genuinely valuable idea practical takeaway clear and actionable advice supporting data facts or statistics to back it up anecdote or story a relatable story that illustrates the point these are fantastic elements on their own but unfortunately they're often drowned out by repetition and irrelevant content I've started using open AI deep research to tackle this issue instead of getting bogged down in repetitive content deep research effortlessly filters out the noise transforming lengthy 300 Page books into concise engaging summaries of just 30 to 50 pages without sacrificing essential insights now realistically 700 to 50 compression is an acceptable filtration of noise for example when I asked it to analyze the 15 decisive battles of the world it extracted Leadership Lessons training insights morale boosters and business applications from each battle giving me exactly what I needed without the fluff and our brains retain information much better when it's delivered in dense meaningful insights rather than stretch thin across hundreds of pages so this isn't just a quicker way to read it's a more thoughtful way to learn now both perplexity and Gro have their own versions of deep research but are nowhere close to open AI deep research and and it's finally a product that's actually worth paying for"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI code generation]\n\n[Opening punch] —AI generating a complete web app (job board) in HTML, CSS, and JavaScript.\n\n[Why it matters] —Current limitations of AI code generation, specifically unclickable links.\n\n[What’s new] —AI code generation of a complex web application from scratch.\n\n[Future outlook] —Future versions of the model will likely address current limitations.\n\n[Vision] —AI can now create complete web applications.\n\n[Closer] —Impressive progress from simple buttons to full web apps."}, {"role": "assistant", "content": "so we're going to do some VIP coding today create a beautiful job board web app using HTML CSS JavaScript in a single HTML file make the UI modern and it's doing its job as you can see it's it's writing the code for the entire thing and here goes the website this is actually reasonably good-look wow can't believe that it's possible that AI made the entire thing a lot of the links are unclickable right now which I assume is a you know something that the next version of the model can solve but it's pretty impressive that we went from being able to do one button or two buttons to making this entire thing from scratch"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Indie hacker builds multiplayer flight simulator using AI]\n[Opening punch] — Indie hacker Peter uses AI (Gro 3, Cursor, LLM) to build a browser-based flight simulator in hours.\n[Why it matters] — Traditional game development is time-consuming and requires significant coding skills.\n[What’s new] —AI-assisted game creation using HTML, vanilla JavaScript, and 3js for 3D graphics.Multiplayer functionality with Python websockets.Real revenue generated from in-game purchases.\n[Future outlook] — AI rendering will transform blocky worlds into photorealistic environments, leading to an explosion of creativity.\n[Vision] — Technology democratizes game creation, allowing people with ideas but limited coding skills to build functioning prototypes quickly.\n[Closer] — AI gaming will be massive, transforming who gets to create."}, {"role": "assistant", "content": "this Indie hacker just built a multiplayer flight simulator the whole thing was coded almost entirely by AI Peter asked cursor and llm like Gro 3 to make a 3D flying game in browser with skyscrapers and within just a few hours he had a functioning flight simulator something he'd never built before now what's cool is that he built it all with HTML and vanilla JavaScript using 3js for the 3D Graphics no complicated game engine under the hood and the back end uses python websockets that broadcast all player position 10 times per second to create a synchronized multiplayer experience every red plane you see is someone else flying in real time what's mind-blowing is that Peter turned this experiment into a real business he added a buy button where players can purchase an F-16 for $29.99 and people actually bought it within days he sold nine f-16s and AD space to a company for $1,000 generating real Revenue now this sparked a wave of creators building what critics might dismiss as AI slop and even Elon Musk took notice commenting that AI gaming will be massive and it makes perfect sense why we're witnessing a transformation in who gets to create suddenly the barriers to game development are crumbling allowing people with ideas but limited coding skills to build functioning prototypes in hours instead of years these AI assisted games might start simple but they're laying the groundwork for something revolutionary once AI rendering transforms these blocky worlds into photo realistic environments we'll see an explosion of creativity this is technology democratizing creation in real time"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI playing Pokémon]\n\n[Opening punch] — Anthropic's AI assistant Claude learned to play Pokémon without specific training.\n\n[Why it matters] — Current gaming AI often needs millions of training iterations.\n\n[What’s new] — Claude 3.7 plans ahead, analyzes game states, and makes strategic decisions, unlike impulsive previous models.It uses general intelligence, vision, memory, and function calls to navigate the game.It developed a personality, naming its Squirtle \"Tsunami.\"\n\n[Future outlook] —AI could potentially solve complex problems in medicine, science, and engineering without specific training.\n\n[Vision] — AI can master complex challenges through reasoning, not just training.\n\n[Closer] —AI's ability to solve problems without training has huge potential."}, {"role": "assistant", "content": "AI just learned to play Pokémon without being trained for it for the past year a small team at anthropic has been obsessed with a weird question can their AI assistant Claude play Pokémon and not by training it specifically on gaming just by letting it figure things out with its general intelligence now early experiments were straight up embarrassing Claude 3.5 Sonet would Panic during mandatory battles wander aimlessly and once even got so stuck in a corner that it formally requested a game reset but then something changed with claw 3.7 Sonic within hours it defeated Brock days later it crushed Misty and the secret was extended thinking unlike previous models that acted on impulse Claude 3.7 actually plans ahead it carefully analyzes the game State considers possible moves and makes strategic decisions before acting this is even more shocking considering that most gaming AI need millions of specialized training iterations Alpha go mastered go by playing itself countless times but Claud just figured it out using general intelligence the setup is surprisingly basic Vision to see the screen memory to store notes and function call to press buttons with just these tools Claude navigates the game World strategizes battles and makes meaningful progress what's fascinating is that while doing all this sophisticated problem solving the AI also developed a surprising amount of Personality like naming its Squirtle tsunami now this isn't just about games if AI can Master complex challenges through pure reasoning without specific training imagine what it could do for Medicine Science or engineering tackling problems it's never seen before"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's GPT 4.5 launch]\n[Opening punch] — OpenAI launches GPT 4.5, a new large language model. Sam Altman praises its ability to provide good advice.\n[Why it matters] — Previous models struggled with accuracy and hallucination.\n[What’s new] — GPT 4.5 uses unsupervised learning to improve knowledge, intuition, and reduce hallucination.It achieves higher accuracy (78%) and lower hallucination (19%) on the PersonQA benchmark compared to GPT-4.It also demonstrates improved text_inputual understanding and emotional nuance.\n[Future outlook] —Internal evaluations show GPT 4.5 outperforms previous models in accuracy and factuality.\n[Vision] — GPT 4.5 represents a different kind of AI intelligence, offering more thoughtful and nuanced responses.\n[Closer] — GPT 4.5 feels like talking to a thoughtful person."}, {"role": "assistant", "content": "open AI just launched GPT 4.5 their newest largest and most knowledgeable AI model yet now Sam Alman describes it as the first model that feels like talking to a thoughtful person he's even been astonished at getting actually good advice from an AI but here's the thing open AI advances these models through two different paradigms unsupervised learning and reasoning while reasoning models think before responding to complex problems GPT 4.5 scales up unsupervised learning to increase World Knowledge improve intuition and reduce h ation and talking about performance on the person QA Benchmark GPT 4.5 achieves 78% accuracy with only a 19% hallucination rate dramatically better than gp4 owes 28% accuracy and 52% hallucination rate while internal evaluations show it outperforms all previous GPT models in accuracy and factuality but where GPT 4.5 really shines is in its deeper knowledge and improved text_inputual understanding the model has been trained with new ignment techniques that make conversations feel warmer more intuitive and emotionally nuanced in demonstrations GPT 4.5 recognized emotional text_input that other models missed offering more thoughtful responses however one key thing to note is that GPT 4.5 isn't designed to be a reasoning model it's described as a different kind of intelligence with a magic to it that hasn't been felt before with previous models"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Anthropic's Claude 3.7 launch]\n[Opening punch] — Anthropic launches Claude 3.7, a powerful new AI model.\n[Why it matters] — Existing AI models have limitations in problem-solving and adaptability.\n[What’s new] — Claude 3.7 offers detailed reasoning, precise control over thinking, and state-of-the-art performance.It can build web apps and write/push code.\n[Future outlook] —N/A\n[Vision] — AI becomes truly useful by adapting to different problems.\n[Closer] — AI becomes truly useful by adapting to different problems."}, {"role": "assistant", "content": "anthropic just launched Claude 3.7 Sonet their most powerful AI yet and it completely changes how AI models think unlike other models that only think one way Claude 3.7 can either give instant responses or show you its detailed reasoning process step by step this extended thinking mode is why one developer reported Claude 3.7 with thinking just solved a problem no other model could solve yet creating the most intricate cloth simulation in p5js while grock 3 and other models had no no usable results and the coolest thing is that developers have precise control over how much thinking the model can do in Benchmark tests Claude 3.7 soned achieved state-of-the-art performance on swe bench verified which measures a model's ability to solve real world software issues replate used it to build entire web applications from scratch where other models completely stalled alongside the model anthropic released clawed code a terminal tool that can read code bases write tests and even push directly to GitHub completing 45 minute tasks in a single pass so this is how AI becomes truly useful by adapting to different problems rather than using the same approach for everything"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Meta's research on thought-to-text technology]\n[Opening punch] — Meta published papers on translating thoughts into text.\n[Why it matters] — Current thought-to-text systems are inaccurate or require invasive brain implants.\n[What’s new] — Meta's AI model predicts text from brain signals with 80% accuracy for sentences, using EEG and MEG sensors.New deep learning architecture.\n[Future outlook] —Technology is not perfect yet, requiring a magnetically shielded room and stillness.\n[Vision] — Potential for silent communication and controlling devices with thoughts.\n[Closer] —Potential for silent communication and controlling devices with thoughts."}, {"role": "assistant", "content": "meta just published two papers showing they can turn thoughts into text with 80% accuracy in real time they used special sensors called meeg and EEG to record tiny magnetic fields from brain activity while 35 people typed sentences then they used a new deep learning architecture brain to quity to train an AI model to predict the sentences just from the brain signals what's Wild is that this new architecture scored 32% character error rate basically for every 100 characters it got 68 right the crazy part is that for some people the model even got entire sentences perfect averaging around 80% accuracy for sentences it hadn't even seen before but that's not all they also took 1,000 brain snapshots every second and tracked the exact moment when thoughts turned into words syllables and even individual letters previous systems either needed brain implants like neuralink or were very inaccurate maxing out at 43% on basic tasks now meta's approach is better but it's still not perfect because me requires people to sit in a magnetically shielded room and stay completely still even small movements like moving the mouth or tongue can corrupt neuroimaging signals that being said when we do manage to turn meeg scanners into variables we could communicate completely silently or control devices with just our thoughts"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI upcoming devices launch in 2026]\n[Opening punch] — Elon Musk's Grok 3, a new large language model, achieves top performance in code generation, complex problem-solving, and real-world tasks.\n[Why it matters] — Existing large language models have limitations in complex tasks and real-world applications.\n[What’s new] — Grok 3 excels at code generation (e.g., 3D animations), complex problem-solving (math, board games), and real-world tasks (chatbot Arena).Features include \"think button\" for step-by-step problem-solving, self-correction, hallucination minimization, \"big brain mode,\" \"deep search,\" \"unhinged mode,\" and voice understanding.\n[Future outlook] — XAI's rapid progress suggests further advancements, potentially including agent technology.\n[Vision] — Grok 3 represents a significant leap in AI capabilities, potentially revolutionizing various fields.\n[Closer] —Grok 3's impressive capabilities and rapid development suggest exciting future innovations in AI."}, {"role": "assistant", "content": "Elon Musk just dropped Gro 3 and it is performing on par with the best models including open eyes o1 and deep seeks R1 for example when prompted to generate code for an animated 3D plot of a launch from Earth to Mars and then back to Earth at the next launch window it figured out the oscillations the next launch window the relative positioning of the planets and did an amazing job running the animation too Gro 3 can tackle complex tasks like analyzing board games and solving math problems using its think button which helps it break down problems step by step much like how humans approach challenges trained on xai supercomputer Colossus built in just 122 days with 100,000 Nvidia h100 gpus it also features self-correction mechanisms and the ability to minimize hallucinations and the results back it up it became the first model to score over 1,400 on chatbot Arena a benchmark that tests llms in real world open-ended tasks but that's not all new features like big brain mode use extra computing power for solving complex problems while deep search combines search with reasoning and unhinged mode allows for more creative unrestricted interactions on top of it grock 3 has also expanded to voice it now understands tone inflection and pacing making it feel like you're talking to a real person but there's a catch grock 3 is only available to Premium Plus X subscribers but considering it took less than 2 years for xai to get to this level and Elon is already hinting at the introduction of an agent we can expect even more surprises in the near future"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Humane AI pin acquisition by HP]\n\n[Opening punch] — Humane AI pin, a tiny AI assistant, sold to HP for $116 million.\n\n[Why it matters] — Smartphones already provide comprehensive AI assistance.\n\n[What’s new] — The pin featured gesture controls, laser projection, and sophisticated AI.\n\n[Future outlook] — HP plans to integrate the technology into computers and conference rooms.\n\n[Vision] — Innovative technology repurposed for smarter devices.\n\n[Closer] — Ambitious failures can transform into something else."}, {"role": "assistant", "content": "the Humane AI pin just shut down and got sold to HP for $116 million way less than the 1 billion they were hoping for and here's why this ambitious device was probably always going to struggle think about it we live in a world where phones aren't just devices there are digital lives the pin tried simplifying this by being a tiny AI assistant you could clip on your shirt but here's the thing it cost $700 plus a monthly suboutpution and it couldn't do most of what your phone already does really well now the pin actually had amazing Tech inside gesture controls laser projection and sophisticated AI but it was fighting an impossible battle when you already have a super powerful computer in your pocket that can do everything it's hard to justify carrying another device that does less but this story isn't over HP bought all this Innovative technology which has over 300 patterns and the team behind it they plan to use it differently to make our computers and conference rooms smarter maybe sometimes the best Innovations come from ambitious failures that transform entirely into something else"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Microsoft's new state of matter for quantum computing]\n[Opening punch] — Microsoft created a new state of matter, topological state, using Topo conductors for a quantum processor.\n[Why it matters] — Traditional quantum computer cubits are fragile and unstable, limiting scalability.\n[What’s new] — Topo conductor-based cubits are faster, more stable, and smaller (100th of a millimeter), enabling millions on a single chip.\n[Future outlook] — Quantum computing could be closer than thought, unlocking innovations like new materials, understanding dark matter, and breaking encryption.\n[Vision] — Topo conductors could revolutionize quantum computing, similar to how semiconductors revolutionized modern computing.\n[Closer] — Microsoft is proving quantum computing could be here sooner than expected."}, {"role": "assistant", "content": "Microsoft just created an entirely new state of matter and it could break Computing forever we all know about solid liquid and gas but after nearly 20 years of research Microsoft says it has created something entirely new a topological State using special materials called Topo conductors and they're using it to power Mayana 1 the first Quantum processor of its kind quantum computers rely on cubits think of them as the building blocks of quantum computers but traditional cubits are extremely fragile and unstable kind of like trying to balance a pencil on its tip making making them difficult to scale and that's where Microsoft's breakthrough changes everything Topo conductor based cubits are faster more stable and significantly smaller about 100th of a millimeter this means we can now fit a million of them on a single chip and since more cubits mean more computational power these chips could solve problems that even all the computers on Earth today combined could not all while fitting in the palm of your hand just as semiconductors made Modern Computing possible Topo conductors could do the same for Quantum Computing by unlocking Innovations we can barely imagine we're talking designing entirely new materials understanding Dark Matter creating Quantum neural networks and maybe even finally breaking modern encryption protocols most thought Quantum Computing was still decades away but Microsoft is proving it could finally be here"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Mumbai Tech Week, Asia's largest AI event]\n[Opening punch] — Mumbai hosts a large AI event with 25,000+ startups and 20+ unicorns.\n[Why it matters] — Networking is crucial for funding and clients in AI.\n[What’s new] —Renowned AI leaders, tech CEOs, and industry leaders will attend.Event includes panel discussions, presentations, workshops, hackathons, and job fairs.\n[Future outlook] — Event is from Feb 28th to March 1st.\n[Vision] — AI will power real-world businesses and industries at an unprecedented scale.\n[Closer] —Don't miss the chance to interact with AI leaders and book tickets now."}, {"role": "assistant", "content": "Mumbai is hosting Asia's largest AI event called Mumbai Tech week and it could be huge for all of us as you all know your network really matters for things like funding and clients especially if you work in AI or plan to work here you should build key relationships and this event may be a way to speed that up with over 25,000 startups and 20 plus unicorns worth more than $60 billion combined Mumbai is the epicenter of innovation across Industries Finance retail media entertainment Pharma sports game in real estate Healthcare hospitality and Telecom mum AI at Mumbai Tech week showcases how AI will power real world businesses and industries at an unprecedented scale this isn't just another AI event it's your chance to interact directly with renowned AI leaders such as Nikki permar who co-authored the influential paper attention is all you need sandya deanan vice president and head of meta India sandep data president of AWS India and South Asia and many other big Tech CEOs even leaders like Mr V vatan MD and CEO of idfc First Bank and dendra FIS chief minister of Maharashtra will be there it's Deep Mind Microsoft meta Ola all in one place and that's not all the event includes panel discussions standup presentations Fireside Chats workshops hackathons job fair and Hands-On experiences and much more so don't just watch this video click the link in the comments to check it out and book your tickets now it's happening from Feb 28th to March 1st"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Video game boss AI]\n\n[Opening punch] — Aerion, a video game boss, uses AI to adapt and learn from battles.\n\n[Why it matters] — Traditional game bosses have predictable patterns.\n\n[What’s new] — Aerion analyzes player teams, learns weaknesses, and creates unpredictable attack patterns.\n\n[Future outlook] —Release in late 2025.\n\n[Vision] —Changes the way players approach boss battles by making them unpredictable and requiring new strategies each time.\n\n[Closer] —Imagine facing Aerion after mastering bosses in games like God of War or Elden Ring."}, {"role": "assistant", "content": "this is aerion the world's first video game Boss that uses AI to beat you unlike traditional video game bosses that follow the same patterns making it easy for players to figure out how to beat them aerion analyzes and learns from each battle and gets smarter as you play it even analyzes every player in your team in real time figuring out who is the weakest who is attacking the hardest and who to take out first ultimately creating the most dangerous and unpredictable attack patterns to beat you this means you can't defeat a ston using the same strategy twice because it's constantly learning developed by we made using nvidia's Ace technology the game is set for release in late 2025 imagine facing a ston after playing games like God of War or Elden ring where bosses have patterns you can memorize and winning is just a matter of practice"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Software engineering's future by 2025]\n[Opening punch] — Sam Alman predicts a major shift in software engineering, exemplified by Andre Karati's \"vibe coding.\"\n[Why it matters] — Traditional coding is meticulous and time-consuming.\n[What’s new] — AI tools like Cursor Composer and Claude Sonet allow developers to give \"vibes\" to generate code, interacting with the AI via voice commands.\n[Future outlook] —The technology is still in its early stages, primarily for personal projects.\n[Vision] — AI transforms software creation, potentially making it more efficient and less reliant on manual coding.\n[Closer] — Embracing AI isn't just about efficiency, but a fundamental shift in how software is built."}, {"role": "assistant", "content": "Sam Alman just made this wild prediction that software engineering by the end of 2025 will look completely different than it does today and we're already seen this happen with something that AI researcher Andre karati calls Vibe coding now traditional coding is like building with detailed blueprints every line matters and every function needs to be precise but karati describes this entirely new way of coding where developers fully give the Vibes using AI tools like cursor composer with Claude Sonet he's changed how he codes entirely he even talks to composer using super whisper so barely touches the keyboard and the most fascinating part is that the code grows beyond what any one person would normally track kapati says he's embracing exponentials he just types things like decrease the padding on the sidebar by half because he's too lazy to find it himself when errors pop up he just copy paste them to the AI without any comment which usually fixes it but are these tools perfect yet no karati says it's mainly for weekend projects at the moment but he thinks we're still doing way too much this isn't even the final form it's like we're watching the future that Sam Alman predicted unfold in real time some developers might resist this change seeing it as a badge of honor to write everything themselves but as kapati shows us embracing AI isn't just about being more efficient it's about transforming how we create software entirely"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI video enhancement technology]\n[Opening punch] — AI can add people/objects to videos, mimicking VFX team work.\n[Why it matters] — Traditional video enhancement is complex and time-consuming.\n[What’s new] — AI automatically adds elements to videos from uploaded video and photo.\n[Future outlook] — Still early stages, struggles with faces, complex movements, and limited output (5 seconds).\n[Vision] — AI-powered video enhancement is rapidly developing.\n[Closer] — AI video enhancement was previously impossible a year ago."}, {"role": "assistant", "content": "this AI can add people and objects to any video P Labs is trying to do what usually takes an entire VFX team but with artificial intelligence here's how it works and where we're at with the technology so traditionally adding something to a video means doing a ton of complex work 3D tracking lighting matches animation it's a whole process that can take days or even weeks Pika is trying to do all of that automatically using AI all you have to do is upload a video and a photo it's pretty interesting but and this is important we're definitely still in the early days the tech struggles with faces and complex human movements they often look a bit uncanny and detailed interactions with the environment aren't quite there yet plus it can only generate about 5 Seconds of output however what's exciting though is seeing how quickly this field is developing a year ago doing any of this with AI would have seemed impossible"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI breakthrough from ByteDance]\n\n[Opening punch] — ByteDance's TikTok parent company releases Omnium 1, an AI video generator.\n\n[Why it matters] — Existing AI models struggle with diverse video inputs (full bodies, odd angles, interactions).\n\n[What’s new] — Omnium 1 generates hyperrealistic videos from photos and audio, handling various inputs and interactions, trained on mixed data types (messy real-world videos).\n\n[Future outlook] —AI-generated content will increase exponentially.\n\n[Vision] — Anyone can create endless, optimized video content.\n\n[Closer] —AI video production is now limitless."}, {"role": "assistant", "content": "China's AI scene just landed another massive breakthrough bite dance yeah Tik tok's parent company dropped omnium 1 and it turns any photo and audio into hyperrealistic videos we hate and we love can one tell me why catulus uh science does not answer why[Music] questions now like other AI models that only do faces or work with only specific angles omnium one handles Everything full body shots weird angles even people interacting with objects previous models wouldn't be able to compete with this and the secret is that bite dance cracked the code for training this AI model with mixed data types it learns from Messy Real World videos that's why it feels so natural it's seen way more of the weird imperfect stuff that makes videos feel human the tech is mind-blowing but let's talk about what this really means we're entering an era where anyone can generate endless perfectly optimized content think about it algorithms reward volume and now you've got an AI that can create infinite variations of videos analyze what works and keep improving it's like having an entire Production Studio that never sleeps"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Humanoid robots learning to move like athletes]\n[Opening punch] — Researchers are training humanoid robots to move like Ronaldo, LeBron, and Kobe.\n[Why it matters] — Robots typically train in simulations, but simulated physics often doesn't match real-world dynamics.\n[What’s new] — A new AI system called ASAP uses pre-trained movements on real robots to improve simulations.It combines traditional physics engines with neural networks to capture real-world movement nuances.\n[Future outlook] — Robots are improving rapidly, with some predicting robot Olympic Games by 2030.\n[Vision] — Robot sports could become more entertaining than human sports.\n[Closer] — Would robot sports be more entertaining than human ones?"}, {"role": "assistant", "content": "researchers are training humanoid robots to move like Ronaldo LeBron and Kobe and they're using something fascinating called ASAP a new AI system that's changing how robots learn movement so usually robots train in simulations first but there's this simal Gap basically simulated physics doesn't match real world Dynamics ASAP solves this by deploying pre-trained movements on real robots recording what happens and then using that data to patch up the simulation think of it as a hybrid system traditional physics engines handle the basics while neural networks capture all the messy real world dynamics that equations miss the robot can then practice millions of times in this improved simulation that actually matches reality right now these robots aren't moving anywhere close to how the legendary athletes move but they're improving rapidly and some predict robot Olympic Games by 2030 which makes me wonder would robot Sports be more entertaining than human ones drop your thoughts below"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's new AI research assistant, Deep Research]\n[Opening punch] — OpenAI launched Deep Research, an AI research assistant.\n[Why it matters] — Existing AI research tools lack in-depth analysis and require manual input.\n[What’s new] — Deep Research searches the web, asks clarifying questions, and synthesizes information into a report (5-30 minutes).It learns from sources to determine what to look for next.\n[Future outlook] —OpenAI claims impressive benchmarks (26.6% accuracy).\n[Vision] — Deep Research promises more thorough and efficient research.\n[Closer] —Real-world testing needed to determine true usefulness."}, {"role": "assistant", "content": "open aai just launched their new AI research assistant called Deep research the interface is pretty straightforward similar to deep seeks R1 thinking system where you just click a button and watch it search the web so let's say you want to research supersonic air travel instead of giving you a quick answer it asks smart questions first to understand exactly what you need then it spends anywhere from 5 to 30 minutes searching the web and putting everything together in one test it went through 29 different sources to create a complete market analysis the cool part is it actually thinks through each step using what it learns from one source to know what to look for next although the performance actually improves the longer it spends thinking and browsing you can't stop it Midway and might see it go off the rails and hallucinate however openi says it hits some impressive benchmarks 26.6% accuracy on Humanity's last exam crushing every other model but these days it feels like every AI company is optimizing their models specifically to Ace these tests and benchmarks so we'll only know how useful deep research really is once we get to test it elves we'll keep you posted on how it performs in real world research tasks"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's new model launch]\n\n[Opening punch] — OpenAI released O3 mini, a new model, performing comparably to top models like DeepSeek's R1.\n\n[Why it matters] — Existing models have limitations in code generation, processing large text chunks, and cost.\n\n[What’s new] — O3 mini excels at STEM field programming, math, and science reasoning. It handles massive text chunks (200k in, 100k out tokens), surpassing other models (e.g., GPT-4, DeepSeek R1).It's significantly cheaper ($1.10-$4.40 per million tokens).Users can adjust the model's thinking intensity.\n\n[Future outlook] — OpenAI is likely to release more fine-tuned models soon, hinted at by Sam Altman.\n\n[Vision] —Improved code generation, handling of large datasets, and affordability for AI users.\n\n[Closer] — OpenAI's consistent model launches suggest a promising future for AI."}, {"role": "assistant", "content": "open aai just dropped a new model O3 mini and it's performing on par with some of the best models out there including deep seeks R1 and as promised it is way better at writing code than most other models now because O3 mini is fine-tuned to enhance reasoning capabilities particularly in stem field programming maths science it can also process text chunks that are massive we're talking 200,000 in and 100,000 out tokens when compared to gp4s 8000 and deeps r1's 128,000 and it's not just powerful it's also way cheaper we're talking 63% cheaper than 01 mini and a whopping 93% cheaper than the full 01 model at just $1.10 and $4.40 per million In-N-Out tokens plus users can even adjust how hard the model thinks from low and medium to high kind of like Switching gears in a car now with open aai consistently launching such fine-tuned models I'm pretty sure they have another model coming soon and Sam Alman is already hinting at it"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Viral video of a robot reacting to abuse.\n\n[Opening punch] — A $70,000 robot is shown reacting to being kicked and bullied by a streamer.\n\n[Why it matters] —Debate about human interaction with robots and AI.\n\n[What’s new] —The robot's reaction is a machine responding to physical forces, but people are emotionally reacting to it.\n\n[Future outlook] — Robots becoming more advanced and lifelike.\n\n[Vision] —Empathy with robots, potentially dangerous or a human trait.\n\n[Closer] —Question of whether empathizing with machines is dangerous or human."}, {"role": "assistant", "content": "this viral video of a $70,000 robot apparently running away from popular streamer Kai sonat after being kicked and bullied has sparked an interesting debate about how we interact with robots M your mom at my boy your wait wait he's extra heavy out watch out what bro this is 70,000 bro so when you watch this clip it looks almost emotional right I mean just look at the comments some people are saying oh poor robot While others are arguing about robot rights and abuse but here's the thing what we're seeing is really just a machine responding to physical forces now these reactions are part of a bigger story about how we relate to Ai and robots back in the 1960s researchers discovered something wild called the Eliza effect in which people formed emotional bonds with a super basic computer program even though they knew it wasn't actually sentient we're seeing something similar happening now but on a much bigger scale so here's the question as these robotss become more advanced and lifelike is it dangerous to empathize with them or is showing compassion even to machines just part of what makes us human"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's new GPT model boosts stem cell production]\n\n[Opening punch] — Yamanaka factors, four proteins, reprogram adult cells into stem cells.\n\n[Why it matters] — Current stem cell production methods are inefficient and difficult to control.\n\n[What’s new] — GPT 4B micro model identified new biological pathways, redesigned Yamanaka factors, boosting efficiency by 50x.\n\n[Future outlook] — AI could potentially reverse aging.\n\n[Vision] —AI can revolutionize stem cell research and potentially extend human lifespan.\n\n[Closer] —If AI can understand aging, how far are we from reversing it?"}, {"role": "assistant", "content": "have you heard of yamanaka factors they're at the center of open's newest model GPT 4B micro that has now boosted stem cell production efficiency by an astounding 50x but what exactly are yamanaka factors discovered by Dr shya yamanaka in 2006 these four specific proteins oct4 socks 2 kf4 and cic can reprogram adult cells into stem cells effectively resetting their biological clock yamanaka factors essentially erase a cell's identity imagine taking a skin cell and stripping it of its skin cell programming so reverts to a blank stem cell- like State once reset this stem cell can then transform into almost any cell type in the body muscle nerve liver or even heart cells but here's the challenge this process has historically been inefficient and difficult to control limiting its practical application and that's exactly where GPT 4B micro came in the model didn't just analyze research or make random predictions it identified new biological Pathways and redesigned the yamanaka factors improving their efficiency by a staggering 50x backed by a massive $180 million investment from Sam Alman retro biosciences a company dedicated to adding 10 years to human life was key to this breakthrough though but this has me thinking if we can use AI to understand the science of Aging how far are we from actually reversing it"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[DeepSeek's AI breakthrough impacting chip stocks]\n\n[Opening punch] — DeepSeek's AI breakthrough dramatically reduces computing power needs, causing a massive drop in chip stock prices (Nvidia, Broadcom, ARM).\n\n[Why it matters] — Current AI development relies heavily on expensive hardware.\n\n[What’s new] — DeepSeek's AI requires significantly less computing power, reducing hardware costs by a factor of 20.\n\n[Future outlook] — Increased accessibility and wider adoption of AI.\n\n[Vision] — AI adoption explosion, reshaping the tech industry.\n\n[Closer] — The \"Jevons Paradox\" suggests increased efficiency leads to increased consumption, potentially driving AI adoption."}, {"role": "assistant", "content": "the US market has crashed by over $1 trillion after deep se's latest AI breakthrough Nvidia crashed 177% broadcom plunged 177% arm fell 10% basically every major chip company took a massive hit why because deep seek just proved you can build powerful AI using way less computing power they achieved what typically cost $100 million in hardware for just $5 million at first glance this means we'll need fewer chips explaining why chip stocks are crashing but here's the thing back in 1865 an economist named jevans noticed something counterintuitive about coal when technology made coal use more efficient instead of using less coal people actually used more why because as something becomes cheaper and more efficient we find more ways to use it the same thing is likely to happen with AI chips even though each AI model needs fewer chips to run the massive drop in cost means way more people in companies can now build and run AI we're not just making AI more efficient we're making it accessible to everyone this temporary Market Panic might actually be missing the bigger picture we're about to see an explosion and AI adoption that's the jevin Paradox in action and it's about to reshape the entire tech industry"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Chinese AI model surpasses ChatGPT on US App Store]\n[Opening punch] — Chinese model DeepSeek, from financial firm Highflyer Quant, dethrones ChatGPT.\n[Why it matters] — Current AI models are expensive to train.\n[What’s new] — DeepSeek uses a novel learning method (r10) based on trial and error, achieving similar performance to OpenAI's models at a fraction of the cost (20x less).\n[Future outlook] —Further technical details in a future YouTube video.\n[Vision] —Challenges the assumption that Chinese tech companies only copy Western ideas, showcasing an innovative approach.\n[Closer] — Subscribe to the YouTube channel for more details."}, {"role": "assistant", "content": "a Chinese model called Deep seek just dethrown chat GPD as the number one app on the US Apple Store it's completely free open- source and performs at the same level as open ai's most powerful models like 01 Pro but here's the fascinating part deep seek isn't even its Creator's main business the company behind it highflyer Quant is actually a financial trading firm full of brilliant math experts who happen to own a bunch of gpus for trading and crypto mining incredibly deep seek started as their side project to make use of those idle gpus but they did something really really clever instead of copying other AI models directly they completely reinvented how AI learns using this new method called r10 while most models learn from examples like here's a question here's the right answer deep seek figures things out through trial and error more like how humans learn essentially learning through millions of trial and error attempts similar to how deep Minds Alpha zero Master chess the cost difference is even mind-blowing while training a model like gp4 costs around $100 million deep seek achieved similar capabilities for Just5 to6 million that's a 20x reduction in cost now it completely changes how we think about Chinese Tech Innovation while many assume Chinese companies just copy Western ideas deep seek shows how China's approach has evolved taking breakthrough Concepts and transforming them into something entirely new however there are even more fascinating technical details and lessons to this story but I'll save those for a full long form video on my YouTube channel make sure to subscribe"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's AI agent launch]\n[Opening punch] — OpenAI launched Operator, its first AI agent.\n[Why it matters] — Current AI limitations in interacting with websites/apps.\n[What’s new] — Operator uses a specialized model (QA-Computer) to interact with websites/apps autonomously, booking a restaurant reservation as a demo.\n[Future outlook] — Operator is live for pro users in the US, with global rollout planned. More agents are hinted at.\n[Vision] — AI agents can interact with websites/apps like humans.\n[Closer] —Operator is already partnered with brands like OpenTable and Uber."}, {"role": "assistant", "content": "breaking news open AI just launched operator its first AI agent it uses the same UI as chat GPT but operates as a fully autonomous agent during the demo it booked a restaurant reservation not by simply surfing the web but by actively navigating the website clicking through options logging in a reservation time checking availability and adjusting to a different time slot if necessary operator is trained on a specialized model that open aai is calling QA computer using agent design specifically for interacting with websites and apps like a human wood open aai has already partnered with Brands like open table and Uber to enhance its functionality not just this Sam Alman also hinted at more agents coming soon with operator already live for pro users in the US and plans to roll out globally soon"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[OpenAI's massive AI data center investment]\n[Opening punch] — OpenAI's $500 billion investment in AI data centers across America.\n[Why it matters] — Current AI development limitations.\n[What’s new] —$100 billion immediate deployment for massive computing facilities.10 massive data centers in Texas (each half a million sq ft).\n[Future outlook] —Expansion to 20 buildings across multiple locations.AI breakthroughs like cancer detection and personalized vaccines in 48 hours.\n[Vision] — Development of artificial general intelligence and potentially super intelligent AI, leading to major economic transformation.\n[Closer] —Beginning of America's golden age."}, {"role": "assistant", "content": "open aai just announced a mind-blowing $500 billion investment to build AI data centers Across America that's the biggest Tech investment in history the project called Stargate will start by deploying $100 billion immediately to construct massive Computing facilities that will power the next generation of AI development for perspective that's about 20 times what we spent on the Manhattan Project in today's money now giants like soft Bank Oracle and mgx have made this possible and this isn't just plans on paper according to Larry Ellison construction is already underway they're building 10 massive data centers in Texas each one half a million square ft that's like eight football fields Under One Roof and they're planning to expand to 20 buildings across multiple locations each Center will be packed with specialized computers working together to push AI capabilities beyond anything we've seen before for example Oracle CEO shared how AI could revolutionize Healthcare they are working on using AI to detect cancer through blood tests and then create personalized cancer vaccines in just 48 Hours think about that from detection to a custom vaccine in 2 days now these kind of breakthroughs are exactly why soft bank's CEO Masa described this as the beginning of America's golden age he believes these data centers will help develop artificial general intelligence very soon and eventually super intelligent AI that could tackle problems we've never been able to solve leading to one of the biggest economic Transformations we've ever seen"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[New dream-hacking technology]\n[Opening punch] — Tiny device hacks dreams, like Inception, but real.\n[Why it matters] — Lucid dreaming is rare, most people don't control their dreams.\n[What’s new] — Transcranial focused ultrasound activates the dlpfc during REM sleep, inducing lucid dreaming.\n[Future outlook] — Technology could make lucid dreaming more common.\n[Vision] —People could control their dreams, potentially leading to innovation.\n[Closer] —History's greatest minds used lucid dreaming, now technology can help everyone."}, {"role": "assistant", "content": "this tiny device plugged into your head lets you hack your dreams turning them from random experiences into Worlds you can actually control just like Inception but unlike the movie it's already working in real Labs so during a regular dream this part of your brain the dorsolateral prefrontal cortex or dlpfc is basically asleep is the command center for decision- making and self-awareness that's why dreams feel so random and you can't tell you're dreaming but in locid dreams something incredible happens the dlpfc wakes up while the rest of your brain stays in dream mode suddenly you have heightened awareness and can control what happens next and that's where this device comes in using transcranial focused ultrasound technology it beams multiple low intensity sound waves that can pass through your skull and Target specific neural circuits by precisely timing these waves during REM sleep it can activate just the dlpfc without affecting anything else creating perfect conditions for lucid dreaming now some of History's Greatest Minds harness this power naturally Tesla visualized his inventions in lucid dreams Edison would nap holding steel balls when they dropped he'd wake up with new ideas and lucid dreaming is so rare most people only experience it once or twice in their lifetime but this technology could change that"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[Resurrection of the woolly mammoth]\n[Opening punch] — Colossal Biosciences is raising $200M to resurrect the woolly mammoth.\n[Why it matters] —Extinct species revival is a complex scientific endeavor.\n[What’s new] —Rewriting DNA, creating hybrids, mapping genomes, and developing artificial WBCs.Significant progress in induced pluripotent stem cells and ancient DNA sequencing.\n[Future outlook] —Splicing mammoth genes into Asian elephants to create cold-resistant hybrids.\n[Vision] —Potential for reintroducing extinct species, but also raises ethical and ecological concerns.\n[Closer] —Raises questions about the ethics and potential consequences of resurrecting extinct species."}, {"role": "assistant", "content": "humans are resurrecting an extinct creature using technology the woly mammoth might be back a company called colossal biosciences just raised $200 million to make it happen they're rewriting DNA turning Asian elephants into Mammoth hybrids mapping extinct genomes and developing artificial WBS all in-house what's crazy is that their Tech has already shown promise they've created induced Flor poent stem cells from Asian elephants a significant step that's crucial to bringing the mammoth back they've sequenced ancient DNA to generate a complete Mammoth genome identifying critical genetic traits like thick fur and cold resistance then using crisper cast 9 a gene editing tool that allows scientists to change DNA in a Cell they're splicing these Mammoth genes into Asian elephants re-engineering them to survive in Arctic conditions but remember jurasic Park the movie was based around the same idea and things didn't end well there so maybe it's worth questioning whether resurrecting the past is innovation or if we're just opening a door to disaster"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[TikTok ban prompting users to download alternative Chinese app Red Note]\n\n[Opening punch] — TikTok ban, millions of users downloading Red Note, a Chinese app, ranking #1 on US App Store.\n\n[Why it matters] — TikTok's ban creates a potential void, and Red Note is filling it.\n\n[What’s new] — Red Note, a TikTok/Instagram hybrid, is gaining popularity.Users are learning Mandarin to use it.\n\n[Future outlook] —Red Note leverages TikTok's influencer network to gain users.\n\n[Vision] — Users prioritize Chinese social media over US government data security concerns.\n\n[Closer] —Users are replacing one Chinese app with another, potentially due to China's strategic timing."}, {"role": "assistant", "content": "since Tik Tok is now getting banned millions of Americans are now downloading another Chinese app called red note it's already number one on the US App Store and users are literally learning Mandarin to use it and this isn't random rednote which is part Tik Tok and part Instagram is number one while lemon8 another Chinese platform is ranking second rather than abandoning Chinese apps Tik Tok users are embracing new ones or maybe China just orchestrated this perfectly they're leveraging Tik tok's massive influencer Network to push red note transforming millions of soon to be banned Tik Tok users into their new audience when Tik Tok vanishes they'll still control where these users go but here is the irony users trust China with their data more than they trust the US government to them this ban represents censorship not security they're turning potential Panic into memes laughing at replacing one Chinese app with another over privacy concerns it's funny how everyone assumed this was about quick dopamine hits from short form content when all users wanted was Chinese social media or did China just perfectly time their alternative moment"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: Sony's PS5 location-based scent technology for gaming.\n\n[Opening punch] — Sony is developing a PS5 experience allowing players to smell in-game scents.\n\n[Why it matters] — Current gaming experiences are limited to visuals and sound; haptic feedback is a recent addition.\n\n[What’s new] —A location-based experience, like stepping into infected tunnels from The Last of Us, immersing players' senses.\n\n[Future outlook] —Proof-of-concept stage, but Sony envisions a future where physical and virtual worlds overlap.\n\n[Vision] —Transforming gaming from a pastime to a lived experience using VR and spatial technology.\n\n[Closer] — Gaming is about to become much more realistic."}, {"role": "assistant", "content": "Sony is working on letting PlayStation players smell in-game scents in real life now this is still in the proof of concept stage but at CES 20125 Sony decided to push gaming into wild new territory and they just showed off a new location-based experience that lets you walk into the world of The Last of Us like actually step into those infected tunnels of Seattle according to Naughty Dogs Neil dman this Tech immerses all of your senses and you would have never experienced The Last of Us quite like this think about it gaming started with just visuals and sound then came hatic feedback so we could feel the action now smell is the next Frontier but this raises some interesting questions like do we really want to smell those infected tunnels some gamers are already joking about which game worlds they definitely don't want to experience with their nose but this is bigger than just adding scents Sony's entire vision is about creating what they call infinite realities where physical and Virtual Worlds fully overlap they're using everything from VR to spatial Tech to transform gaming from something we play into something we truly live whether we're ready or not gaming is about to get a lot more real"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context:[AI agents transforming the workplace]\n\n[Opening punch] — IT departments will manage AI agents.\n\n[Why it matters] — Current AI tools are limited, often generating inconsistent code.\n\n[What’s new] — AI agents can plan and execute entire projects, including database structure and code consistency.They orchestrate workflows across multiple tasks.\n\n[Future outlook] —AI agents will handle complex tasks independently.\n\n[Vision] —Shift from managing computers to managing AI agents.\n\n[Closer] —AI agents are like super smart digital assistants."}, {"role": "assistant", "content": "the IT department of every company is going to be the HR department of AI agents in the future now let me tell you why this makes perfect sense so we're entering this era called agentic AI which completely changes how we work with machines now these aren't just regular AI chat Bots they're more like digital employees who can plan and complete entire projects on their own and I got to see this firsthand when we built autocode Pro in 2023 see most AI tools were just generating random Snippets of code but we wanted to push further we created an AI that could plan and execute entire projects give it a task and it would figure out everything the database structure all the different files how they connect and even keeping all the variable names consistent throughout the project that's different from older AI which would get confused and mess things up but here's where it gets really interesting these new AI agents don't just do one thing they orchestrate entire workflows imagine an AI that can hop between booking your flights managing your email and building entire applications all while keeping track of how everything fits together it's like having a super smart digital assistant that actually understands the big picture that's why Jensen's prediction about it departments makes so much sense we're moving from managing computers to managing AI agents who can plan decide and act independently"}]}
{"messages":[{"role": "system", "content":"You are a social media manager having 5 year of experience who writes instgram reel script"},{"role": "user", "content": "Context: [5-step UI design process\n\n1. Define Project & Gather Requirements\n    - Clarify project goals, audience, and brand guidelines.\n    - Collect assets and understand the visual and emotional direction.\n2. Create Wireframes & User Flows\n    - Map out user journeys and key interactions.\n    - Develop low-fidelity wireframes to outline structure and functionality.\n3. Establish Visual Style (Mood Board & Brand Kit)\n    - Assemble a mood board for visual inspiration.\n    - Define the brand kit (color palette, typography, logo, tagline).\n4. Design UI Elements & Layouts\n    - Design high-fidelity interfaces for key screens, prioritizing mobile-first.\n    - Select and integrate UI resources (icons, images, illustrations).\n5. Ensure Responsiveness & Handover\n    - Adapt designs for all device sizes (responsive design).\n    - Prepare and deliver final assets to developers or stakeholders.\n\n[Opening punch] — Want your product to feel premium—even in MVP stage? Use this 5-step UI design process that helps startups scale smart.\n\n[Why it matters] — Many startups struggle with building interfaces that attract and retain users, leading to lost customers and slow growth.\n\n[Future outlook] — Following this process ensures your product scales smoothly, delivers a seamless user experience, and stands out in competitive markets.\n\n[Closer] — Want UI designs that work for your business? Explore Growigh.com and read our blog for the full guide. And click the follow button to never miss an update."}, {"role": "assistant", "content": "Want your product to feel premium—even at the MVP stage? \nToo many startups have products that work but look basic and fail to engage users.\nThe good news? Creating a beautiful, functional UI doesn’t have to be overwhelming—you just need a clear, proven strategy.\nI’m sharing a 5-step UI design process that helps startups scale smart.\n\nStep 1: Define project goals and gather all assets upfront—logos, brand guidelines, content—so your vision is clear.\nStep 2: Now, Create wireframes and user flows to map exactly how users navigate your product before diving into design.\nWhy does everything look inconsistent?\nStep 3: Build a mood board and brand kit to keep colors, typography, and style consistent.\nBut the design feels empty and disconnected.\nStep 4: Design high-fidelity screens with matching icons and visuals that bring the experience to life.\nStep 5: Make sure your design is responsive across devices and deliver final assets to your developers.\n\nHere’s the pro tip : Prioritize key user actions. Make sure the most important buttons and features easy to find and interact with.\n\nWant UI designs that work for your business? Explore Growigh.com and read our blog for the full guide."}]}
